#!/usr/bin/env python3
"""
üß™ TESTE DE INTEGRA√á√ÉO - DETEC√á√ÉO DE NOVOS FLUXOS VIA LOGS
üìê CoCoT + ToT + ReAct - Baseado em C√≥digo Real
üö´ PROIBIDO: Testes sint√©ticos, gen√©ricos ou aleat√≥rios
‚úÖ PERMITIDO: Apenas testes baseados em c√≥digo real do Omni Writer

Teste de integra√ß√£o para o framework de detec√ß√£o de fluxos via logs.
Valida detec√ß√£o autom√°tica de novos fluxos baseados em logs reais.

Tracing ID: FLOW_DETECTION_INTEGRATION_20250127_001
Data/Hora: 2025-01-27T19:00:00Z
Vers√£o: 1.0
"""

import pytest
import json
import tempfile
import os
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any

# Importa o framework de detec√ß√£o de fluxos
from scripts.flow_detection_framework import (
    FlowDetectionFramework,
    LogEntry,
    FlowPattern,
    FlowDetectionResult,
    LogSource
)

TRACING_ID = "FLOW_DETECTION_INTEGRATION_20250127_001"

class TestFlowDetectionIntegration:
    """
    Teste de integra√ß√£o para o framework de detec√ß√£o de fluxos.
    
    Baseado em logs reais do Omni Writer:
    - logs/structured_logs.json
    - logs/pipeline_multi_diag.log
    - logs/decisions_2025-01-27.log
    """
    
    @pytest.fixture(autouse=True)
    def setup_test_environment(self):
        """Configura ambiente de teste com logs reais."""
        self.tracing_id = TRACING_ID
        self.test_db_path = "tests/integration/test_flow_detection_integration.db"
        
        # Cria diret√≥rio tempor√°rio para logs de teste
        self.temp_dir = tempfile.mkdtemp()
        self.test_logs_dir = Path(self.temp_dir) / "logs"
        self.test_logs_dir.mkdir()
        
        # Copia logs reais para diret√≥rio de teste
        self._copy_real_logs()
        
        # Inicializa framework com banco de teste
        self.framework = FlowDetectionFramework(db_path=self.test_db_path)
        
        yield
        
        # Limpeza ap√≥s teste
        if os.path.exists(self.test_db_path):
            os.remove(self.test_db_path)
        shutil.rmtree(self.temp_dir)
    
    def _copy_real_logs(self):
        """Copia logs reais do Omni Writer para teste."""
        real_logs_dir = Path("logs")
        
        # Copia logs estruturados
        if (real_logs_dir / "structured_logs.json").exists():
            shutil.copy2(
                real_logs_dir / "structured_logs.json",
                self.test_logs_dir / "structured_logs.json"
            )
        
        # Copia logs de pipeline
        if (real_logs_dir / "pipeline_multi_diag.log").exists():
            shutil.copy2(
                real_logs_dir / "pipeline_multi_diag.log",
                self.test_logs_dir / "pipeline_multi_diag.log"
            )
        
        # Copia logs de decis√µes
        if (real_logs_dir / "decisions_2025-01-27.log").exists():
            shutil.copy2(
                real_logs_dir / "decisions_2025-01-27.log",
                self.test_logs_dir / "decisions_2025-01-27.log"
            )
    
    def _create_test_log_entry(self, timestamp: str, level: str, message: str, 
                              service: str, endpoint: str = None) -> str:
        """Cria entrada de log de teste baseada em formato real."""
        log_entry = {
            "timestamp": timestamp,
            "level": level,
            "message": message,
            "service": service,
            "endpoint": endpoint,
            "request_id": f"req-{hash(message) % 10000}",
            "user_id": "test-user-123",
            "session_id": "session-456",
            "metadata": {
                "test": True,
                "tracing_id": self.tracing_id
            }
        }
        return json.dumps(log_entry)
    
    def test_flow_detection_with_real_logs(self):
        """
        Testa detec√ß√£o de fluxos com logs reais do Omni Writer.
        
        Cen√°rio Real: Analisa logs reais de produ√ß√£o para identificar
        fluxos n√£o testados e gerar sugest√µes de teste.
        """
        # Verifica se logs reais existem
        structured_logs = self.test_logs_dir / "structured_logs.json"
        pipeline_logs = self.test_logs_dir / "pipeline_multi_diag.log"
        decision_logs = self.test_logs_dir / "decisions_2025-01-27.log"
        
        if not any([structured_logs.exists(), pipeline_logs.exists(), decision_logs.exists()]):
            pytest.skip("Logs reais n√£o encontrados para teste")
        
        # Analisa logs estruturados
        if structured_logs.exists():
            result = self.framework.analyze_logs(
                str(structured_logs),
                source_name="application_logs"
            )
            
            # Valida√ß√µes baseadas em comportamento real
            assert result is not None, "Resultado da an√°lise n√£o deve ser None"
            assert result.total_logs_analyzed > 0, "Deve analisar logs reais"
            assert result.new_flows_detected >= 0, "Deve detectar fluxos (pode ser 0 se todos j√° conhecidos)"
        
        # Analisa logs de pipeline
        if pipeline_logs.exists():
            result = self.framework.analyze_logs(
                str(pipeline_logs),
                source_name="pipeline_logs"
            )
            
            # Valida√ß√µes espec√≠ficas para logs de pipeline
            assert result is not None, "Resultado da an√°lise n√£o deve ser None"
            assert result.total_logs_analyzed > 0, "Deve analisar logs de pipeline"
        
        # Analisa logs de decis√µes
        if decision_logs.exists():
            result = self.framework.analyze_logs(
                str(decision_logs),
                source_name="decision_logs"
            )
            
            # Valida√ß√µes espec√≠ficas para logs de decis√µes
            assert result is not None, "Resultado da an√°lise n√£o deve ser None"
            assert result.total_logs_analyzed > 0, "Deve analisar logs de decis√µes"
    
    def test_new_flow_detection_real_scenarios(self):
        """
        Testa detec√ß√£o de novos fluxos baseados em cen√°rios reais.
        
        Cen√°rio Real: Identifica fluxos cr√≠ticos como pagamentos, autentica√ß√£o
        e gera√ß√£o de artigos que s√£o de alto risco se n√£o testados.
        """
        # Cria arquivo de log com cen√°rios reais do Omni Writer
        test_log_file = self.test_logs_dir / "test_real_scenarios.json"
        
        # Cen√°rios reais baseados em c√≥digo do Omni Writer
        real_scenarios = [
            self._create_test_log_entry(
                "2025-01-27T15:30:22.000Z",
                "INFO",
                "Iniciando gera√ß√£o de artigo via OpenAI",
                "openai_gateway",
                "/generate"
            ),
            self._create_test_log_entry(
                "2025-01-27T15:30:23.000Z",
                "INFO",
                "Artigo gerado com sucesso",
                "generation_service",
                "/status"
            ),
            self._create_test_log_entry(
                "2025-01-27T15:30:24.000Z",
                "INFO",
                "Iniciando download do artigo",
                "storage_service",
                "/download"
            ),
            self._create_test_log_entry(
                "2025-01-27T15:31:00.000Z",
                "INFO",
                "Processando pagamento via Stripe",
                "stripe_gateway",
                "/payment"
            ),
            self._create_test_log_entry(
                "2025-01-27T15:31:01.000Z",
                "INFO",
                "Webhook do Stripe recebido",
                "payment_service",
                "/webhook"
            )
        ]
        
        with open(test_log_file, 'w') as f:
            for entry in real_scenarios:
                f.write(entry + '\n')
        
        # Executa an√°lise
        result = self.framework.analyze_logs(
            str(test_log_file),
            source_name="application_logs"
        )
        
        # Valida√ß√µes espec√≠ficas para cen√°rios reais
        assert result is not None, "Resultado da an√°lise n√£o deve ser None"
        assert result.total_logs_analyzed == 5, f"Esperado 5 logs, obtido {result.total_logs_analyzed}"
        
        # Verifica se fluxos cr√≠ticos foram identificados
        assert len(result.high_risk_flows) > 0, "Deve identificar fluxos de alto risco"
        
        # Verifica se sugest√µes foram geradas para fluxos cr√≠ticos
        assert result.test_suggestions_generated > 0, "Deve gerar sugest√µes para fluxos cr√≠ticos"
    
    def test_flow_pattern_extraction_real_data(self):
        """
        Testa extra√ß√£o de padr√µes de fluxo baseados em dados reais.
        
        Cen√°rio Real: Extrai padr√µes de fluxo de logs reais do Omni Writer
        para identificar sequ√™ncias de opera√ß√µes n√£o testadas.
        """
        # Cria arquivo de log com padr√µes reais
        test_log_file = self.test_logs_dir / "test_patterns.json"
        
        # Padr√µes baseados em c√≥digo real do Omni Writer
        pattern_entries = [
            self._create_test_log_entry(
                "2025-01-27T18:00:00.000Z",
                "INFO",
                "Usu√°rio autenticado",
                "auth_service",
                "/login"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:01.000Z",
                "INFO",
                "Blog criado com sucesso",
                "blog_service",
                "/blogs/create"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:02.000Z",
                "INFO",
                "Categoria adicionada",
                "blog_service",
                "/blogs/categories"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:03.000Z",
                "INFO",
                "Artigo gerado",
                "generation_service",
                "/generate"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:04.000Z",
                "INFO",
                "Arquivo exportado",
                "export_service",
                "/export"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:05.000Z",
                "INFO",
                "Sess√£o encerrada",
                "auth_service",
                "/logout"
            )
        ]
        
        with open(test_log_file, 'w') as f:
            for entry in pattern_entries:
                f.write(entry + '\n')
        
        # Executa an√°lise
        result = self.framework.analyze_logs(
            str(test_log_file),
            source_name="application_logs"
        )
        
        # Valida√ß√µes para extra√ß√£o de padr√µes
        assert result is not None, "Resultado da an√°lise n√£o deve ser None"
        assert result.total_logs_analyzed == 6, f"Esperado 6 logs, obtido {result.total_logs_analyzed}"
        
        # Verifica se padr√µes foram extra√≠dos
        assert result.new_flows_detected > 0, "Deve detectar novos padr√µes de fluxo"
        
        # Verifica se fluxos cont√™m endpoints esperados
        report = self.framework.generate_report()
        most_frequent = report.get("most_frequent_flows", [])
        
        # Verifica se fluxos cont√™m servi√ßos reais do Omni Writer
        services_found = set()
        for flow in most_frequent:
            if "name" in flow:
                services_found.add(flow["name"])
        
        # Verifica se servi√ßos cr√≠ticos foram detectados
        expected_services = {"auth_service", "blog_service", "generation_service"}
        assert len(services_found.intersection(expected_services)) > 0, "Deve detectar servi√ßos cr√≠ticos"
    
    def test_risk_score_calculation_real_scenarios(self):
        """
        Testa c√°lculo de risk score baseado em cen√°rios reais.
        
        Cen√°rio Real: Calcula risk score para fluxos cr√≠ticos do Omni Writer
        como pagamentos, autentica√ß√£o e gera√ß√£o de artigos.
        """
        # Cria arquivo de log com cen√°rios de diferentes n√≠veis de risco
        test_log_file = self.test_logs_dir / "test_risk_logs.json"
        
        # Cen√°rios com diferentes n√≠veis de risco baseados em c√≥digo real
        risk_entries = [
            # Fluxo de baixo risco
            self._create_test_log_entry(
                "2025-01-27T18:00:00.000Z",
                "INFO",
                "P√°gina inicial acessada",
                "web_service",
                "/"
            ),
            # Fluxo de m√©dio risco
            self._create_test_log_entry(
                "2025-01-27T18:00:01.000Z",
                "INFO",
                "Usu√°rio logado",
                "auth_service",
                "/login"
            ),
            # Fluxo de alto risco
            self._create_test_log_entry(
                "2025-01-27T18:00:02.000Z",
                "INFO",
                "Pagamento processado",
                "stripe_gateway",
                "/payment"
            ),
            # Fluxo cr√≠tico
            self._create_test_log_entry(
                "2025-01-27T18:00:03.000Z",
                "INFO",
                "Gera√ß√£o de artigo via OpenAI",
                "openai_gateway",
                "/generate"
            )
        ]
        
        with open(test_log_file, 'w') as f:
            for entry in risk_entries:
                f.write(entry + '\n')
        
        # Executa an√°lise
        result = self.framework.analyze_logs(
            str(test_log_file),
            source_name="application_logs"
        )
        
        # Valida√ß√µes para c√°lculo de risk score
        assert result is not None, "Resultado da an√°lise n√£o deve ser None"
        
        # Verifica se fluxos de alto risco foram identificados
        assert len(result.high_risk_flows) > 0, "Deve identificar fluxos de alto risco"
        
        # Verifica se sugest√µes foram geradas para fluxos cr√≠ticos
        assert result.test_suggestions_generated > 0, "Deve gerar sugest√µes para fluxos cr√≠ticos"
        
        # Verifica se relat√≥rio cont√©m m√©tricas de risco
        report = self.framework.generate_report()
        assert "statistics" in report, "Relat√≥rio deve conter estat√≠sticas"
        
        stats = report["statistics"]
        assert "high_risk_patterns" in stats, "Estat√≠sticas devem incluir padr√µes de alto risco"
        assert "avg_risk_score" in stats, "Estat√≠sticas devem incluir score m√©dio de risco"
    
    def test_test_suggestions_generation(self):
        """
        Testa gera√ß√£o de sugest√µes de teste baseadas em fluxos reais.
        
        Cen√°rio Real: Gera sugest√µes de teste para fluxos n√£o testados
        baseados em an√°lise de logs reais do Omni Writer.
        """
        # Cria arquivo de log com fluxos n√£o testados
        test_log_file = self.test_logs_dir / "test_untested_flows.json"
        
        # Fluxos que podem n√£o estar testados (baseados em c√≥digo real)
        untested_flows = [
            self._create_test_log_entry(
                "2025-01-27T19:00:00.000Z",
                "INFO",
                "Webhook recebido do Stripe",
                "webhook_service",
                "/webhook/stripe"
            ),
            self._create_test_log_entry(
                "2025-01-27T19:00:01.000Z",
                "INFO",
                "Processamento de reembolso",
                "refund_service",
                "/refund"
            ),
            self._create_test_log_entry(
                "2025-01-27T19:00:02.000Z",
                "INFO",
                "Exporta√ß√£o em lote",
                "batch_export_service",
                "/export/batch"
            )
        ]
        
        with open(test_log_file, 'w') as f:
            for entry in untested_flows:
                f.write(entry + '\n')
        
        # Executa an√°lise
        result = self.framework.analyze_logs(
            str(test_log_file),
            source_name="application_logs"
        )
        
        # Valida√ß√µes para gera√ß√£o de sugest√µes
        assert result is not None, "Resultado da an√°lise n√£o deve ser None"
        assert result.total_logs_analyzed == 3, f"Esperado 3 logs, obtido {result.total_logs_analyzed}"
        
        # Verifica se fluxos n√£o testados foram identificados
        assert len(result.untested_flows) > 0, "Deve identificar fluxos n√£o testados"
        
        # Verifica se sugest√µes foram geradas
        assert result.test_suggestions_generated > 0, "Deve gerar sugest√µes de teste"
    
    def test_flow_detection_report_generation(self):
        """
        Testa gera√ß√£o de relat√≥rios de detec√ß√£o de fluxos.
        
        Cen√°rio Real: Gera relat√≥rios completos com m√©tricas, padr√µes
        e sugest√µes baseados em an√°lise de logs reais.
        """
        # Executa an√°lise com logs reais se dispon√≠veis
        structured_logs = self.test_logs_dir / "structured_logs.json"
        
        if structured_logs.exists():
            self.framework.analyze_logs(
                str(structured_logs),
                source_name="application_logs"
            )
        
        # Gera relat√≥rio
        report = self.framework.generate_report()
        
        # Valida√ß√µes para relat√≥rio
        assert report is not None, "Relat√≥rio n√£o deve ser None"
        assert "tracing_id" in report, "Relat√≥rio deve conter tracing_id"
        assert "timestamp" in report, "Relat√≥rio deve conter timestamp"
        assert "statistics" in report, "Relat√≥rio deve conter estat√≠sticas"
        
        # Verifica estat√≠sticas
        stats = report["statistics"]
        assert "total_patterns" in stats, "Estat√≠sticas devem incluir total de padr√µes"
        assert "tested_patterns" in stats, "Estat√≠sticas devem incluir padr√µes testados"
        assert "untested_patterns" in stats, "Estat√≠sticas devem incluir padr√µes n√£o testados"
        assert "coverage_percentage" in stats, "Estat√≠sticas devem incluir porcentagem de cobertura"
        
        # Verifica se relat√≥rio cont√©m fluxos mais frequentes
        assert "most_frequent_flows" in report, "Relat√≥rio deve incluir fluxos mais frequentes"
        assert "high_risk_flows" in report, "Relat√≥rio deve incluir fluxos de alto risco"
        assert "untested_flows" in report, "Relat√≥rio deve incluir fluxos n√£o testados"
        
        # Verifica se relat√≥rio cont√©m sugest√µes
        assert "test_suggestions" in report, "Relat√≥rio deve incluir sugest√µes de teste"
        
        # Valida formato de sugest√µes
        suggestions = report["test_suggestions"]
        assert isinstance(suggestions, list), "Sugest√µes devem ser uma lista"
        
        # Verifica se sugest√µes s√£o baseadas em c√≥digo real
        for suggestion in suggestions[:5]:  # Verifica apenas as primeiras 5
            assert "endpoint" in suggestion or "service" in suggestion, "Sugest√£o deve referenciar endpoint ou servi√ßo"
            assert "description" in suggestion, "Sugest√£o deve ter descri√ß√£o"
            assert "risk_score" in suggestion, "Sugest√£o deve ter risk score"
    
    def test_flow_detection_integration_with_telemetry(self):
        """
        Testa integra√ß√£o entre detec√ß√£o de fluxos e telemetria.
        
        Cen√°rio Real: Integra detec√ß√£o de fluxos com sistema de telemetria
        para monitoramento cont√≠nuo de novos fluxos.
        """
        # Simula integra√ß√£o com telemetria
        from scripts.telemetry_framework import telemetry_decorator
        
        @telemetry_decorator
        def test_flow_detection_with_telemetry():
            """Testa detec√ß√£o de fluxos com telemetria integrada."""
            # Cria log de teste
            test_log_file = self.test_logs_dir / "test_telemetry_integration.json"
            
            telemetry_entries = [
                self._create_test_log_entry(
                    "2025-01-27T20:00:00.000Z",
                    "INFO",
                    "Telemetria iniciada",
                    "telemetry_service",
                    "/telemetry/start"
                ),
                self._create_test_log_entry(
                    "2025-01-27T20:00:01.000Z",
                    "INFO",
                    "M√©tricas coletadas",
                    "metrics_service",
                    "/metrics/collect"
                ),
                self._create_test_log_entry(
                    "2025-01-27T20:00:02.000Z",
                    "INFO",
                    "Telemetria finalizada",
                    "telemetry_service",
                    "/telemetry/end"
                )
            ]
            
            with open(test_log_file, 'w') as f:
                for entry in telemetry_entries:
                    f.write(entry + '\n')
            
            # Executa an√°lise
            result = self.framework.analyze_logs(
                str(test_log_file),
                source_name="application_logs"
            )
            
            return result
        
        # Executa teste com telemetria
        result = test_flow_detection_with_telemetry()
        
        # Valida√ß√µes para integra√ß√£o com telemetria
        assert result is not None, "Resultado da an√°lise n√£o deve ser None"
        assert result.total_logs_analyzed == 3, f"Esperado 3 logs, obtido {result.total_logs_analyzed}"
        
        # Verifica se fluxos de telemetria foram detectados
        assert result.new_flows_detected >= 0, "Deve detectar fluxos de telemetria"
        
        # Verifica se sugest√µes foram geradas
        assert result.test_suggestions_generated >= 0, "Deve gerar sugest√µes para fluxos de telemetria" 