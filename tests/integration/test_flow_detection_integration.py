#!/usr/bin/env python3
"""
ğŸ§ª TESTE DE INTEGRAÃ‡ÃƒO - DETECÃ‡ÃƒO DE NOVOS FLUXOS VIA LOGS
ğŸ“ CoCoT + ToT + ReAct - Baseado em CÃ³digo Real
ğŸš« PROIBIDO: Testes sintÃ©ticos, genÃ©ricos ou aleatÃ³rios
âœ… PERMITIDO: Apenas testes baseados em cÃ³digo real do Omni Writer

Teste de integraÃ§Ã£o para o framework de detecÃ§Ã£o de fluxos via logs.
Valida detecÃ§Ã£o automÃ¡tica de novos fluxos baseados em logs reais.

Tracing ID: FLOW_DETECTION_INTEGRATION_20250127_001
Data/Hora: 2025-01-27T19:00:00Z
VersÃ£o: 1.0
"""

import pytest
import json
import tempfile
import os
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any

# Importa o framework de detecÃ§Ã£o de fluxos
from scripts.flow_detection_framework import (
    FlowDetectionFramework,
    LogEntry,
    FlowPattern,
    FlowDetectionResult,
    LogSource
)

TRACING_ID = "FLOW_DETECTION_INTEGRATION_20250127_001"

class TestFlowDetectionIntegration:
    """
    Teste de integraÃ§Ã£o para o framework de detecÃ§Ã£o de fluxos.
    
    Baseado em logs reais do Omni Writer:
    - logs/structured_logs.json
    - logs/pipeline_multi_diag.log
    - logs/decisions_2025-01-27.log
    """
    
    @pytest.fixture(autouse=True)
    def setup_test_environment(self):
        """Configura ambiente de teste com logs reais."""
        self.tracing_id = TRACING_ID
        self.test_db_path = "tests/integration/test_flow_detection_integration.db"
        
        # Cria diretÃ³rio temporÃ¡rio para logs de teste
        self.temp_dir = tempfile.mkdtemp()
        self.test_logs_dir = Path(self.temp_dir) / "logs"
        self.test_logs_dir.mkdir()
        
        # Copia logs reais para diretÃ³rio de teste
        self._copy_real_logs()
        
        # Inicializa framework com banco de teste
        self.framework = FlowDetectionFramework(db_path=self.test_db_path)
        
        yield
        
        # Limpeza apÃ³s teste
        if os.path.exists(self.test_db_path):
            os.remove(self.test_db_path)
        shutil.rmtree(self.temp_dir)
    
    def _copy_real_logs(self):
        """Copia logs reais do Omni Writer para teste."""
        real_logs_dir = Path("logs")
        
        # Copia logs estruturados
        if (real_logs_dir / "structured_logs.json").exists():
            shutil.copy2(
                real_logs_dir / "structured_logs.json",
                self.test_logs_dir / "structured_logs.json"
            )
        
        # Copia logs de pipeline
        if (real_logs_dir / "pipeline_multi_diag.log").exists():
            shutil.copy2(
                real_logs_dir / "pipeline_multi_diag.log",
                self.test_logs_dir / "pipeline_multi_diag.log"
            )
        
        # Copia logs de decisÃµes
        if (real_logs_dir / "decisions_2025-01-27.log").exists():
            shutil.copy2(
                real_logs_dir / "decisions_2025-01-27.log",
                self.test_logs_dir / "decisions_2025-01-27.log"
            )
    
    def _create_test_log_entry(self, timestamp: str, level: str, message: str, 
                              service: str, endpoint: str = None) -> str:
        """Cria entrada de log de teste baseada em formato real."""
        log_entry = {
            "timestamp": timestamp,
            "level": level,
            "message": message,
            "service": service,
            "endpoint": endpoint,
            "request_id": f"req-{hash(message) % 10000}",
            "user_id": "test-user-123",
            "session_id": "session-456",
            "metadata": {
                "test": True,
                "tracing_id": self.tracing_id
            }
        }
        return json.dumps(log_entry)
    
    def test_flow_detection_with_real_logs(self):
        """
        Testa detecÃ§Ã£o de fluxos com logs reais do Omni Writer.
        
        CenÃ¡rio Real: Analisa logs reais de produÃ§Ã£o para identificar
        fluxos nÃ£o testados e gerar sugestÃµes de teste.
        """
        # Verifica se logs reais existem
        structured_logs = self.test_logs_dir / "structured_logs.json"
        pipeline_logs = self.test_logs_dir / "pipeline_multi_diag.log"
        decision_logs = self.test_logs_dir / "decisions_2025-01-27.log"
        
        if not any([structured_logs.exists(), pipeline_logs.exists(), decision_logs.exists()]):
            pytest.skip("Logs reais nÃ£o encontrados para teste")
        
        # Analisa logs estruturados
        if structured_logs.exists():
            result = self.framework.analyze_logs(
                str(structured_logs),
                source_name="application_logs"
            )
            
            # ValidaÃ§Ãµes baseadas em comportamento real
            assert result is not None, "Resultado da anÃ¡lise nÃ£o deve ser None"
            assert result.total_logs_analyzed > 0, "Deve analisar logs reais"
            assert result.new_flows_detected >= 0, "Deve detectar fluxos (pode ser 0 se todos jÃ¡ conhecidos)"
        
        # Analisa logs de pipeline
        if pipeline_logs.exists():
            result = self.framework.analyze_logs(
                str(pipeline_logs),
                source_name="pipeline_logs"
            )
            
            # ValidaÃ§Ãµes especÃ­ficas para logs de pipeline
            assert result is not None, "Resultado da anÃ¡lise nÃ£o deve ser None"
            assert result.total_logs_analyzed > 0, "Deve analisar logs de pipeline"
        
        # Analisa logs de decisÃµes
        if decision_logs.exists():
            result = self.framework.analyze_logs(
                str(decision_logs),
                source_name="decision_logs"
            )
            
            # ValidaÃ§Ãµes especÃ­ficas para logs de decisÃµes
            assert result is not None, "Resultado da anÃ¡lise nÃ£o deve ser None"
            assert result.total_logs_analyzed > 0, "Deve analisar logs de decisÃµes"
    
    def test_new_flow_detection_real_scenarios(self):
        """
        Testa detecÃ§Ã£o de novos fluxos baseados em cenÃ¡rios reais.
        
        CenÃ¡rio Real: Identifica fluxos crÃ­ticos como pagamentos, autenticaÃ§Ã£o
        e geraÃ§Ã£o de artigos que sÃ£o de alto risco se nÃ£o testados.
        """
        # Cria arquivo de log com cenÃ¡rios reais do Omni Writer
        test_log_file = self.test_logs_dir / "test_real_scenarios.json"
        
        # CenÃ¡rios reais baseados em cÃ³digo do Omni Writer
        real_scenarios = [
            self._create_test_log_entry(
                "2025-01-27T15:30:22.000Z",
                "INFO",
                "Iniciando geraÃ§Ã£o de artigo via OpenAI",
                "openai_gateway",
                "/generate"
            ),
            self._create_test_log_entry(
                "2025-01-27T15:30:23.000Z",
                "INFO",
                "Artigo gerado com sucesso",
                "generation_service",
                "/status"
            ),
            self._create_test_log_entry(
                "2025-01-27T15:30:24.000Z",
                "INFO",
                "Iniciando download do artigo",
                "storage_service",
                "/download"
            ),
            self._create_test_log_entry(
                "2025-01-27T15:31:00.000Z",
                "INFO",
                "Processando pagamento via Stripe",
                "stripe_gateway",
                "/payment"
            ),
            self._create_test_log_entry(
                "2025-01-27T15:31:01.000Z",
                "INFO",
                "Webhook do Stripe recebido",
                "payment_service",
                "/webhook"
            )
        ]
        
        with open(test_log_file, 'w') as f:
            for entry in real_scenarios:
                f.write(entry + '\n')
        
        # Executa anÃ¡lise
        result = self.framework.analyze_logs(
            str(test_log_file),
            source_name="application_logs"
        )
        
        # ValidaÃ§Ãµes especÃ­ficas para cenÃ¡rios reais
        assert result is not None, "Resultado da anÃ¡lise nÃ£o deve ser None"
        assert result.total_logs_analyzed == 5, f"Esperado 5 logs, obtido {result.total_logs_analyzed}"
        
        # Verifica se fluxos crÃ­ticos foram identificados
        assert len(result.high_risk_flows) > 0, "Deve identificar fluxos de alto risco"
        
        # Verifica se sugestÃµes foram geradas para fluxos crÃ­ticos
        assert result.test_suggestions_generated > 0, "Deve gerar sugestÃµes para fluxos crÃ­ticos"
    
    def test_flow_pattern_extraction_real_data(self):
        """
        Testa extraÃ§Ã£o de padrÃµes de fluxo baseados em dados reais.
        
        CenÃ¡rio Real: Extrai padrÃµes de fluxo de logs reais do Omni Writer
        para identificar sequÃªncias de operaÃ§Ãµes nÃ£o testadas.
        """
        # Cria arquivo de log com padrÃµes reais
        test_log_file = self.test_logs_dir / "test_patterns.json"
        
        # PadrÃµes baseados em cÃ³digo real do Omni Writer
        pattern_entries = [
            self._create_test_log_entry(
                "2025-01-27T18:00:00.000Z",
                "INFO",
                "UsuÃ¡rio autenticado",
                "auth_service",
                "/login"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:01.000Z",
                "INFO",
                "Blog criado com sucesso",
                "blog_service",
                "/blogs/create"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:02.000Z",
                "INFO",
                "Categoria adicionada",
                "blog_service",
                "/blogs/categories"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:03.000Z",
                "INFO",
                "Artigo gerado",
                "generation_service",
                "/generate"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:04.000Z",
                "INFO",
                "Arquivo exportado",
                "export_service",
                "/export"
            ),
            self._create_test_log_entry(
                "2025-01-27T18:00:05.000Z",
                "INFO",
                "SessÃ£o encerrada",
                "auth_service",
                "/logout"
            )
        ]
        
        with open(test_log_file, 'w') as f:
            for entry in pattern_entries:
                f.write(entry + '\n')
        
        # Executa anÃ¡lise
        result = self.framework.analyze_logs(
            str(test_log_file),
            source_name="application_logs"
        )
        
        # ValidaÃ§Ãµes para extraÃ§Ã£o de padrÃµes
        assert result is not None, "Resultado da anÃ¡lise nÃ£o deve ser None"
        assert result.total_logs_analyzed == 6, f"Esperado 6 logs, obtido {result.total_logs_analyzed}"
        
        # Verifica se padrÃµes foram extraÃ­dos
        assert result.new_flows_detected > 0, "Deve detectar novos padrÃµes de fluxo"
        
        # Verifica se fluxos contÃªm endpoints esperados
        report = self.framework.generate_report()
        most_frequent = report.get("most_frequent_flows", [])
        
        # Verifica se fluxos contÃªm serviÃ§os reais do Omni Writer
        services_found = set()
        for flow in most_frequent:
            if "name" in flow:
                services_found.add(flow["name"])
        
        # Verifica se serviÃ§os crÃ­ticos foram detectados
        expected_services = {"auth_service", "blog_service", "generation_service"}
        assert len(services_found.intersection(expected_services)) > 0, "Deve detectar serviÃ§os crÃ­ticos"
    
    def test_risk_score_calculation_real_scenarios(self):
        """
        Testa cÃ¡lculo de risk score baseado em cenÃ¡rios reais.
        
        CenÃ¡rio Real: Calcula risk score para fluxos crÃ­ticos do Omni Writer
        como pagamentos, autenticaÃ§Ã£o e geraÃ§Ã£o de artigos.
        """
        # Cria arquivo de log com cenÃ¡rios de diferentes nÃ­veis de risco
        test_log_file = self.test_logs_dir / "test_risk_logs.json"
        
        # CenÃ¡rios com diferentes nÃ­veis de risco baseados em cÃ³digo real
        risk_entries = [
            # Fluxo de baixo risco
            self._create_test_log_entry(
                "2025-01-27T18:00:00.000Z",
                "INFO",
                "PÃ¡gina inicial acessada",
                "web_service",
                "/"
            ),
            # Fluxo de mÃ©dio risco
            self._create_test_log_entry(
                "2025-01-27T18:00:01.000Z",
                "INFO",
                "UsuÃ¡rio logado",
                "auth_service",
                "/login"
            ),
            # Fluxo de alto risco
            self._create_test_log_entry(
                "2025-01-27T18:00:02.000Z",
                "INFO",
                "Pagamento processado",
                "stripe_gateway",
                "/payment"
            ),
            # Fluxo crÃ­tico
            self._create_test_log_entry(
                "2025-01-27T18:00:03.000Z",
                "INFO",
                "GeraÃ§Ã£o de artigo via OpenAI",
                "openai_gateway",
                "/generate"
            )
        ]
        
        with open(test_log_file, 'w') as f:
            for entry in risk_entries:
                f.write(entry + '\n')
        
        # Executa anÃ¡lise
        result = self.framework.analyze_logs(
            str(test_log_file),
            source_name="application_logs"
        )
        
        # ValidaÃ§Ãµes para cÃ¡lculo de risk score
        assert result is not None, "Resultado da anÃ¡lise nÃ£o deve ser None"
        
        # Verifica se fluxos de alto risco foram identificados
        assert len(result.high_risk_flows) > 0, "Deve identificar fluxos de alto risco"
        
        # Verifica se sugestÃµes foram geradas para fluxos crÃ­ticos
        assert result.test_suggestions_generated > 0, "Deve gerar sugestÃµes para fluxos crÃ­ticos"
        
        # Verifica se relatÃ³rio contÃ©m mÃ©tricas de risco
        report = self.framework.generate_report()
        assert "statistics" in report, "RelatÃ³rio deve conter estatÃ­sticas"
        
        stats = report["statistics"]
        assert "high_risk_patterns" in stats, "EstatÃ­sticas devem incluir padrÃµes de alto risco"
        assert "avg_risk_score" in stats, "EstatÃ­sticas devem incluir score mÃ©dio de risco"
    
    def test_test_suggestions_generation(self):
        """
        Testa geraÃ§Ã£o de sugestÃµes de teste baseadas em fluxos reais.
        
        CenÃ¡rio Real: Gera sugestÃµes de teste para fluxos nÃ£o testados
        baseados em anÃ¡lise de logs reais do Omni Writer.
        """
        # Cria arquivo de log com fluxos nÃ£o testados
        test_log_file = self.test_logs_dir / "test_untested_flows.json"
        
        # Fluxos que podem nÃ£o estar testados (baseados em cÃ³digo real)
        untested_flows = [
            self._create_test_log_entry(
                "2025-01-27T19:00:00.000Z",
                "INFO",
                "Webhook recebido do Stripe",
                "webhook_service",
                "/webhook/stripe"
            ),
            self._create_test_log_entry(
                "2025-01-27T19:00:01.000Z",
                "INFO",
                "Processamento de reembolso",
                "refund_service",
                "/refund"
            ),
            self._create_test_log_entry(
                "2025-01-27T19:00:02.000Z",
                "INFO",
                "ExportaÃ§Ã£o em lote",
                "batch_export_service",
                "/export/batch"
            )
        ]
        
        with open(test_log_file, 'w') as f:
            for entry in untested_flows:
                f.write(entry + '\n')
        
        # Executa anÃ¡lise
        result = self.framework.analyze_logs(
            str(test_log_file),
            source_name="application_logs"
        )
        
        # ValidaÃ§Ãµes para geraÃ§Ã£o de sugestÃµes
        assert result is not None, "Resultado da anÃ¡lise nÃ£o deve ser None"
        assert result.total_logs_analyzed == 3, f"Esperado 3 logs, obtido {result.total_logs_analyzed}"
        
        # Verifica se fluxos nÃ£o testados foram identificados
        assert len(result.untested_flows) > 0, "Deve identificar fluxos nÃ£o testados"
        
        # Verifica se sugestÃµes foram geradas
        assert result.test_suggestions_generated > 0, "Deve gerar sugestÃµes de teste"
    
    def test_flow_detection_report_generation(self):
        """
        Testa geraÃ§Ã£o de relatÃ³rios de detecÃ§Ã£o de fluxos.
        
        CenÃ¡rio Real: Gera relatÃ³rios completos com mÃ©tricas, padrÃµes
        e sugestÃµes baseados em anÃ¡lise de logs reais.
        """
        # Executa anÃ¡lise com logs reais se disponÃ­veis
        structured_logs = self.test_logs_dir / "structured_logs.json"
        
        if structured_logs.exists():
            self.framework.analyze_logs(
                str(structured_logs),
                source_name="application_logs"
            )
        
        # Gera relatÃ³rio
        report = self.framework.generate_report()
        
        # ValidaÃ§Ãµes para relatÃ³rio
        assert report is not None, "RelatÃ³rio nÃ£o deve ser None"
        assert "tracing_id" in report, "RelatÃ³rio deve conter tracing_id"
        assert "timestamp" in report, "RelatÃ³rio deve conter timestamp"
        assert "statistics" in report, "RelatÃ³rio deve conter estatÃ­sticas"
        
        # Verifica estatÃ­sticas
        stats = report["statistics"]
        assert "total_patterns" in stats, "EstatÃ­sticas devem incluir total de padrÃµes"
        assert "tested_patterns" in stats, "EstatÃ­sticas devem incluir padrÃµes testados"
        assert "untested_patterns" in stats, "EstatÃ­sticas devem incluir padrÃµes nÃ£o testados"
        assert "coverage_percentage" in stats, "EstatÃ­sticas devem incluir porcentagem de cobertura"
        
        # Verifica se relatÃ³rio contÃ©m fluxos mais frequentes
        assert "most_frequent_flows" in report, "RelatÃ³rio deve incluir fluxos mais frequentes"
        assert "high_risk_flows" in report, "RelatÃ³rio deve incluir fluxos de alto risco"
        assert "untested_flows" in report, "RelatÃ³rio deve incluir fluxos nÃ£o testados"
        
        # Verifica se relatÃ³rio contÃ©m sugestÃµes
        assert "test_suggestions" in report, "RelatÃ³rio deve incluir sugestÃµes de teste"
        
        # Valida formato de sugestÃµes
        suggestions = report["test_suggestions"]
        assert isinstance(suggestions, list), "SugestÃµes devem ser uma lista"
        
        # Verifica se sugestÃµes sÃ£o baseadas em cÃ³digo real
        for suggestion in suggestions[:5]:  # Verifica apenas as primeiras 5
            assert "endpoint" in suggestion or "service" in suggestion, "SugestÃ£o deve referenciar endpoint ou serviÃ§o"
            assert "description" in suggestion, "SugestÃ£o deve ter descriÃ§Ã£o"
            assert "risk_score" in suggestion, "SugestÃ£o deve ter risk score"
    
    def test_flow_detection_integration_with_telemetry(self):
        """
        Testa integraÃ§Ã£o entre detecÃ§Ã£o de fluxos e telemetria.
        
        CenÃ¡rio Real: Integra detecÃ§Ã£o de fluxos com sistema de telemetria
        para monitoramento contÃ­nuo de novos fluxos.
        """
        # Simula integraÃ§Ã£o com telemetria
        from scripts.telemetry_framework import telemetry_decorator
        
        @telemetry_decorator
        def test_flow_detection_with_telemetry():
            """Testa detecÃ§Ã£o de fluxos com telemetria integrada."""
            # Cria log de teste
            test_log_file = self.test_logs_dir / "test_telemetry_integration.json"
            
            telemetry_entries = [
                self._create_test_log_entry(
                    "2025-01-27T20:00:00.000Z",
                    "INFO",
                    "Telemetria iniciada",
                    "telemetry_service",
                    "/telemetry/start"
                ),
                self._create_test_log_entry(
                    "2025-01-27T20:00:01.000Z",
                    "INFO",
                    "MÃ©tricas coletadas",
                    "metrics_service",
                    "/metrics/collect"
                ),
                self._create_test_log_entry(
                    "2025-01-27T20:00:02.000Z",
                    "INFO",
                    "Telemetria finalizada",
                    "telemetry_service",
                    "/telemetry/end"
                )
            ]
            
            with open(test_log_file, 'w') as f:
                for entry in telemetry_entries:
                    f.write(entry + '\n')
            
            # Executa anÃ¡lise
            result = self.framework.analyze_logs(
                str(test_log_file),
                source_name="application_logs"
            )
            
            return result
        
        # Executa teste com telemetria
        result = test_flow_detection_with_telemetry()
        
        # ValidaÃ§Ãµes para integraÃ§Ã£o com telemetria
        assert result is not None, "Resultado da anÃ¡lise nÃ£o deve ser None"
        assert result.total_logs_analyzed == 3, f"Esperado 3 logs, obtido {result.total_logs_analyzed}"
        
        # Verifica se fluxos de telemetria foram detectados
        assert result.new_flows_detected >= 0, "Deve detectar fluxos de telemetria"
        
        # Verifica se sugestÃµes foram geradas
        assert result.test_suggestions_generated >= 0, "Deve gerar sugestÃµes para fluxos de telemetria" 