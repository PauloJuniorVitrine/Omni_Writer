#!/usr/bin/env python3
"""
ğŸ” VALIDAÃ‡ÃƒO SIMPLES - FRAMEWORK DE DETECÃ‡ÃƒO DE FLUXOS
ğŸ“ CoCoT + ToT + ReAct - Baseado em CÃ³digo Real
ğŸš« PROIBIDO: Testes sintÃ©ticos, genÃ©ricos ou aleatÃ³rios
âœ… PERMITIDO: Apenas testes baseados em cÃ³digo real do Omni Writer

Script de validaÃ§Ã£o simples que demonstra o framework sem dependÃªncias externas.
Analisa logs reais do Omni Writer e gera relatÃ³rio de validaÃ§Ã£o.

Tracing ID: FLOW_DETECTION_VALIDATION_20250127_001
Data/Hora: 2025-01-27T18:30:00Z
VersÃ£o: 1.0
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any

TRACING_ID = "FLOW_DETECTION_VALIDATION_20250127_001"

def validate_log_files():
    """Valida se os arquivos de log reais existem."""
    print(f"[{TRACING_ID}] Validando arquivos de log...")
    
    logs_dir = Path("logs")
    required_logs = [
        "structured_logs.json",
        "pipeline_multi_diag.log",
        "decisions_2025-01-27.log"
    ]
    
    found_logs = []
    missing_logs = []
    
    for log_file in required_logs:
        log_path = logs_dir / log_file
        if log_path.exists():
            found_logs.append(log_file)
            print(f"  âœ… {log_file} - Encontrado")
        else:
            missing_logs.append(log_file)
            print(f"  âŒ {log_file} - NÃ£o encontrado")
    
    return found_logs, missing_logs

def analyze_structured_logs():
    """Analisa logs estruturados reais."""
    print(f"\n[{TRACING_ID}] Analisando logs estruturados...")
    
    log_path = Path("logs/structured_logs.json")
    if not log_path.exists():
        print("  âŒ Arquivo de logs estruturados nÃ£o encontrado")
        return None
    
    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            logs = [json.loads(line) for line in f if line.strip()]
        
        print(f"  ğŸ“Š {len(logs)} entradas de log analisadas")
        
        # AnÃ¡lise bÃ¡sica
        services = set()
        levels = set()
        endpoints = set()
        
        for log in logs:
            services.add(log.get('service', 'unknown'))
            levels.add(log.get('level', 'unknown'))
            if 'endpoint' in log:
                endpoints.add(log['endpoint'])
        
        print(f"  ğŸ”§ ServiÃ§os encontrados: {len(services)}")
        print(f"  ğŸ“ NÃ­veis de log: {', '.join(levels)}")
        print(f"  ğŸŒ Endpoints: {len(endpoints)}")
        
        return {
            'total_entries': len(logs),
            'services': list(services),
            'levels': list(levels),
            'endpoints': list(endpoints)
        }
        
    except Exception as e:
        print(f"  âŒ Erro ao analisar logs: {e}")
        return None

def analyze_pipeline_logs():
    """Analisa logs de pipeline reais."""
    print(f"\n[{TRACING_ID}] Analisando logs de pipeline...")
    
    log_path = Path("logs/pipeline_multi_diag.log")
    if not log_path.exists():
        print("  âŒ Arquivo de logs de pipeline nÃ£o encontrado")
        return None
    
    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        print(f"  ğŸ“Š {len(lines)} linhas de log analisadas")
        
        # AnÃ¡lise de padrÃµes
        pipeline_starts = 0
        generate_calls = 0
        testing_mentions = 0
        
        for line in lines:
            if "Iniciando pipeline multi" in line:
                pipeline_starts += 1
            if "Chamando generate_article" in line:
                generate_calls += 1
            if "TESTING=" in line:
                testing_mentions += 1
        
        print(f"  ğŸ”„ InicializaÃ§Ãµes de pipeline: {pipeline_starts}")
        print(f"  ğŸ“ Chamadas de geraÃ§Ã£o: {generate_calls}")
        print(f"  ğŸ§ª MenÃ§Ãµes de teste: {testing_mentions}")
        
        return {
            'total_lines': len(lines),
            'pipeline_starts': pipeline_starts,
            'generate_calls': generate_calls,
            'testing_mentions': testing_mentions
        }
        
    except Exception as e:
        print(f"  âŒ Erro ao analisar logs de pipeline: {e}")
        return None

def analyze_decision_logs():
    """Analisa logs de decisÃµes reais."""
    print(f"\n[{TRACING_ID}] Analisando logs de decisÃµes...")
    
    log_path = Path("logs/decisions_2025-01-27.log")
    if not log_path.exists():
        print("  âŒ Arquivo de logs de decisÃµes nÃ£o encontrado")
        return None
    
    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        print(f"  ğŸ“Š {len(lines)} linhas de log analisadas")
        
        # AnÃ¡lise de decisÃµes
        test_decisions = 0
        coverage_decisions = 0
        risk_decisions = 0
        
        for line in lines:
            if "test" in line.lower():
                test_decisions += 1
            if "coverage" in line.lower():
                coverage_decisions += 1
            if "risk" in line.lower():
                risk_decisions += 1
        
        print(f"  ğŸ§ª DecisÃµes sobre testes: {test_decisions}")
        print(f"  ğŸ“ˆ DecisÃµes sobre cobertura: {coverage_decisions}")
        print(f"  âš ï¸ DecisÃµes sobre risco: {risk_decisions}")
        
        return {
            'total_lines': len(lines),
            'test_decisions': test_decisions,
            'coverage_decisions': coverage_decisions,
            'risk_decisions': risk_decisions
        }
        
    except Exception as e:
        print(f"  âŒ Erro ao analisar logs de decisÃµes: {e}")
        return None

def detect_flow_patterns(analysis_results):
    """Detecta padrÃµes de fluxo baseados na anÃ¡lise."""
    print(f"\n[{TRACING_ID}] Detectando padrÃµes de fluxo...")
    
    patterns = []
    
    # PadrÃµes baseados em logs estruturados
    if analysis_results.get('structured_logs'):
        structured = analysis_results['structured_logs']
        
        # PadrÃ£o de monitoramento
        if any('monitoring' in service for service in structured['services']):
            patterns.append({
                'name': 'Fluxo de Monitoramento',
                'description': 'Detectado atravÃ©s de serviÃ§os de monitoramento',
                'risk_score': 80,
                'services': [s for s in structured['services'] if 'monitoring' in s],
                'is_tested': False
            })
        
        # PadrÃ£o de API
        if structured['endpoints']:
            patterns.append({
                'name': 'Fluxo de API',
                'description': 'Detectado atravÃ©s de endpoints de API',
                'risk_score': 120,
                'endpoints': structured['endpoints'],
                'is_tested': False
            })
    
    # PadrÃµes baseados em logs de pipeline
    if analysis_results.get('pipeline_logs'):
        pipeline = analysis_results['pipeline_logs']
        
        if pipeline['generate_calls'] > 0:
            patterns.append({
                'name': 'Fluxo de GeraÃ§Ã£o de Artigos',
                'description': 'Detectado atravÃ©s de chamadas de geraÃ§Ã£o',
                'risk_score': 150,
                'frequency': pipeline['generate_calls'],
                'is_tested': True
            })
    
    # PadrÃµes baseados em logs de decisÃµes
    if analysis_results.get('decision_logs'):
        decision = analysis_results['decision_logs']
        
        if decision['test_decisions'] > 0:
            patterns.append({
                'name': 'Fluxo de DecisÃµes de Teste',
                'description': 'Detectado atravÃ©s de decisÃµes sobre testes',
                'risk_score': 90,
                'frequency': decision['test_decisions'],
                'is_tested': True
            })
    
    print(f"  ğŸ¯ {len(patterns)} padrÃµes de fluxo detectados")
    
    for pattern in patterns:
        status = "âœ… Testado" if pattern.get('is_tested') else "âŒ NÃ£o Testado"
        print(f"    â€¢ {pattern['name']} (Risk: {pattern['risk_score']}) - {status}")
    
    return patterns

def generate_validation_report(analysis_results, patterns):
    """Gera relatÃ³rio de validaÃ§Ã£o."""
    print(f"\n[{TRACING_ID}] Gerando relatÃ³rio de validaÃ§Ã£o...")
    
    report = {
        'validation_info': {
            'tracing_id': TRACING_ID,
            'timestamp': datetime.now().isoformat(),
            'description': 'ValidaÃ§Ã£o do Framework de DetecÃ§Ã£o de Fluxos',
            'based_on_real_logs': True
        },
        'log_analysis': analysis_results,
        'flow_patterns': patterns,
        'statistics': {
            'total_patterns': len(patterns),
            'tested_patterns': sum(1 for p in patterns if p.get('is_tested')),
            'untested_patterns': sum(1 for p in patterns if not p.get('is_tested')),
            'high_risk_patterns': sum(1 for p in patterns if p.get('risk_score', 0) >= 100),
            'avg_risk_score': sum(p.get('risk_score', 0) for p in patterns) / len(patterns) if patterns else 0
        }
    }
    
    # Calcula taxa de cobertura
    if report['statistics']['total_patterns'] > 0:
        coverage_rate = (report['statistics']['tested_patterns'] / report['statistics']['total_patterns']) * 100
        report['statistics']['coverage_rate'] = coverage_rate
    else:
        report['statistics']['coverage_rate'] = 0
    
    return report

def print_validation_summary(report):
    """Imprime resumo da validaÃ§Ã£o."""
    print("\n" + "="*80)
    print("ğŸ” VALIDAÃ‡ÃƒO - FRAMEWORK DE DETECÃ‡ÃƒO DE FLUXOS")
    print("="*80)
    
    validation_info = report['validation_info']
    stats = report['statistics']
    
    print(f"ğŸ“Š Tracing ID: {validation_info['tracing_id']}")
    print(f"ğŸ•’ Timestamp: {validation_info['timestamp']}")
    print(f"ğŸ“ Baseado em logs reais: {validation_info['based_on_real_logs']}")
    
    print(f"\nğŸ“ˆ ESTATÃSTICAS DE VALIDAÃ‡ÃƒO:")
    print(f"   â€¢ Total de padrÃµes: {stats['total_patterns']}")
    print(f"   â€¢ PadrÃµes testados: {stats['tested_patterns']}")
    print(f"   â€¢ PadrÃµes nÃ£o testados: {stats['untested_patterns']}")
    print(f"   â€¢ PadrÃµes de alto risco: {stats['high_risk_patterns']}")
    print(f"   â€¢ Score mÃ©dio de risco: {stats['avg_risk_score']:.1f}")
    print(f"   â€¢ Taxa de cobertura: {stats['coverage_rate']:.1f}%")
    
    if report['flow_patterns']:
        print(f"\nğŸ¯ PADRÃ•ES DETECTADOS:")
        for pattern in report['flow_patterns']:
            status = "âœ…" if pattern.get('is_tested') else "âŒ"
            print(f"   {status} {pattern['name']} (Risk: {pattern['risk_score']})")
            print(f"      ğŸ“ {pattern['description']}")
    
    print("\n" + "="*80)

def save_validation_report(report):
    """Salva relatÃ³rio de validaÃ§Ã£o."""
    output_dir = Path("tests/integration/reports")
    output_dir.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%dT%H%M%SZ")
    output_file = output_dir / f"flow_detection_validation_{timestamp}.json"
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ’¾ RelatÃ³rio salvo: {output_file}")
        return output_file
    except Exception as e:
        print(f"\nâŒ Erro ao salvar relatÃ³rio: {e}")
        return None

def main():
    """FunÃ§Ã£o principal da validaÃ§Ã£o."""
    print(f"[{TRACING_ID}] Iniciando validaÃ§Ã£o do framework de detecÃ§Ã£o de fluxos")
    
    try:
        # Valida arquivos de log
        found_logs, missing_logs = validate_log_files()
        
        if not found_logs:
            print(f"\nâŒ Nenhum arquivo de log encontrado. ValidaÃ§Ã£o abortada.")
            return 1
        
        # Analisa logs
        analysis_results = {}
        
        structured_analysis = analyze_structured_logs()
        if structured_analysis:
            analysis_results['structured_logs'] = structured_analysis
        
        pipeline_analysis = analyze_pipeline_logs()
        if pipeline_analysis:
            analysis_results['pipeline_logs'] = pipeline_analysis
        
        decision_analysis = analyze_decision_logs()
        if decision_analysis:
            analysis_results['decision_logs'] = decision_analysis
        
        if not analysis_results:
            print(f"\nâŒ Nenhuma anÃ¡lise foi possÃ­vel. ValidaÃ§Ã£o abortada.")
            return 1
        
        # Detecta padrÃµes de fluxo
        patterns = detect_flow_patterns(analysis_results)
        
        # Gera relatÃ³rio
        report = generate_validation_report(analysis_results, patterns)
        
        # Imprime resumo
        print_validation_summary(report)
        
        # Salva relatÃ³rio
        output_file = save_validation_report(report)
        
        if output_file:
            print(f"\nâœ… ValidaÃ§Ã£o concluÃ­da com sucesso!")
            print(f"ğŸ“„ RelatÃ³rio completo: {output_file}")
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ Erro na validaÃ§Ã£o: {e}")
        return 1

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code) 