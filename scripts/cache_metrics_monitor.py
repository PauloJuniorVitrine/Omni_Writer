#!/usr/bin/env python3
"""
Monitor de MÃ©tricas de Cache para Omni Writer.
Monitora hit/miss ratio, performance e saÃºde do cache Redis.
"""

import os
import sys
import time
import json
import argparse
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import logging

# Adiciona o diretÃ³rio raiz ao path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from shared.intelligent_cache import IntelligentCache
from shared.config import REDIS_URL

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('cache_monitor')

class CacheMetricsMonitor:
    """
    Monitor de mÃ©tricas de cache em tempo real.
    
    Funcionalidades:
    - Monitoramento contÃ­nuo de hit/miss ratio
    - Alertas de performance
    - RelatÃ³rios de saÃºde do cache
    - AnÃ¡lise de tendÃªncias
    """
    
    def __init__(self, redis_url: Optional[str] = None, interval: int = 30):
        self.redis_url = redis_url or REDIS_URL
        self.interval = interval
        self.cache = IntelligentCache(redis_url=self.redis_url, enable_metrics=True)
        self.history = []
        self.alerts = []
        
        # Thresholds para alertas
        self.thresholds = {
            'hit_ratio_min': 70.0,  # Hit ratio mÃ­nimo
            'error_rate_max': 5.0,  # Taxa de erro mÃ¡xima
            'response_time_max': 100,  # Tempo de resposta mÃ¡ximo (ms)
            'cache_size_max': 1000  # Tamanho mÃ¡ximo do cache local
        }
    
    def collect_metrics(self) -> Dict:
        """
        Coleta mÃ©tricas atuais do cache.
        
        Returns:
            DicionÃ¡rio com mÃ©tricas coletadas
        """
        start_time = time.time()
        
        try:
            # Coleta mÃ©tricas bÃ¡sicas
            metrics = self.cache.get_metrics()
            
            # Adiciona timestamp
            metrics['timestamp'] = datetime.now().isoformat()
            metrics['response_time_ms'] = round((time.time() - start_time) * 1000, 2)
            
            # Coleta informaÃ§Ãµes adicionais
            cache_info = self.cache.get_cache_info()
            metrics.update(cache_info)
            
            # Calcula taxas
            total_requests = metrics.get('total_requests', 0)
            if total_requests > 0:
                metrics['error_rate'] = (metrics.get('errors', 0) / total_requests) * 100
            else:
                metrics['error_rate'] = 0.0
            
            return metrics
            
        except Exception as e:
            logger.error(f"Erro ao coletar mÃ©tricas: {e}")
            return {
                'timestamp': datetime.now().isoformat(),
                'error': str(e),
                'response_time_ms': round((time.time() - start_time) * 1000, 2)
            }
    
    def check_alerts(self, metrics: Dict) -> List[Dict]:
        """
        Verifica se hÃ¡ alertas baseados nas mÃ©tricas.
        
        Args:
            metrics: MÃ©tricas coletadas
        
        Returns:
            Lista de alertas
        """
        alerts = []
        
        # Verifica hit ratio
        hit_ratio = metrics.get('hit_ratio', 0)
        if hit_ratio < self.thresholds['hit_ratio_min']:
            alerts.append({
                'type': 'warning',
                'message': f'Hit ratio baixo: {hit_ratio}% (mÃ­nimo: {self.thresholds["hit_ratio_min"]}%)',
                'metric': 'hit_ratio',
                'value': hit_ratio,
                'threshold': self.thresholds['hit_ratio_min']
            })
        
        # Verifica taxa de erro
        error_rate = metrics.get('error_rate', 0)
        if error_rate > self.thresholds['error_rate_max']:
            alerts.append({
                'type': 'error',
                'message': f'Taxa de erro alta: {error_rate}% (mÃ¡ximo: {self.thresholds["error_rate_max"]}%)',
                'metric': 'error_rate',
                'value': error_rate,
                'threshold': self.thresholds['error_rate_max']
            })
        
        # Verifica tempo de resposta
        response_time = metrics.get('response_time_ms', 0)
        if response_time > self.thresholds['response_time_max']:
            alerts.append({
                'type': 'warning',
                'message': f'Tempo de resposta alto: {response_time}ms (mÃ¡ximo: {self.thresholds["response_time_max"]}ms)',
                'metric': 'response_time',
                'value': response_time,
                'threshold': self.thresholds['response_time_max']
            })
        
        # Verifica tamanho do cache local
        local_cache_size = metrics.get('local_cache_size', 0)
        if local_cache_size > self.thresholds['cache_size_max']:
            alerts.append({
                'type': 'info',
                'message': f'Cache local grande: {local_cache_size} itens (mÃ¡ximo: {self.thresholds["cache_size_max"]})',
                'metric': 'local_cache_size',
                'value': local_cache_size,
                'threshold': self.thresholds['cache_size_max']
            })
        
        # Verifica disponibilidade do Redis
        if not metrics.get('redis_available', False):
            alerts.append({
                'type': 'error',
                'message': 'Redis nÃ£o disponÃ­vel - usando cache local',
                'metric': 'redis_available',
                'value': False,
                'threshold': True
            })
        
        return alerts
    
    def print_metrics(self, metrics: Dict, alerts: List[Dict]):
        """
        Imprime mÃ©tricas formatadas no console.
        
        Args:
            metrics: MÃ©tricas coletadas
            alerts: Alertas gerados
        """
        print("\n" + "="*60)
        print(f"ðŸ“Š MÃ‰TRICAS DE CACHE - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("="*60)
        
        # MÃ©tricas principais
        print(f"ðŸŽ¯ Hit Ratio: {metrics.get('hit_ratio', 0)}%")
        print(f"ðŸ“ˆ Total Requests: {metrics.get('total_requests', 0)}")
        print(f"âœ… Hits: {metrics.get('hits', 0)}")
        print(f"âŒ Misses: {metrics.get('misses', 0)}")
        print(f"ðŸ’¾ Sets: {metrics.get('sets', 0)}")
        print(f"ðŸ—‘ï¸  Deletes: {metrics.get('deletes', 0)}")
        print(f"âš ï¸  Errors: {metrics.get('errors', 0)}")
        print(f"ðŸ“Š Error Rate: {metrics.get('error_rate', 0):.2f}%")
        print(f"â±ï¸  Response Time: {metrics.get('response_time_ms', 0)}ms")
        
        # Status do Redis
        redis_status = "ðŸŸ¢ DisponÃ­vel" if metrics.get('redis_available', False) else "ðŸ”´ IndisponÃ­vel"
        print(f"ðŸ”´ Redis: {redis_status}")
        
        # Cache local
        print(f"ðŸ’» Cache Local: {metrics.get('local_cache_size', 0)} itens")
        
        # Alertas
        if alerts:
            print("\nðŸš¨ ALERTAS:")
            for alert in alerts:
                icon = "âš ï¸" if alert['type'] == 'warning' else "âŒ" if alert['type'] == 'error' else "â„¹ï¸"
                print(f"  {icon} {alert['message']}")
        else:
            print("\nâœ… Nenhum alerta detectado")
        
        print("="*60)
    
    def save_metrics(self, metrics: Dict, filename: Optional[str] = None):
        """
        Salva mÃ©tricas em arquivo JSON.
        
        Args:
            metrics: MÃ©tricas coletadas
            filename: Nome do arquivo (opcional)
        """
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"cache_metrics_{timestamp}.json"
        
        filepath = os.path.join('logs', filename)
        
        try:
            os.makedirs('logs', exist_ok=True)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(metrics, f, indent=2, ensure_ascii=False)
            
            logger.info(f"MÃ©tricas salvas em: {filepath}")
            
        except Exception as e:
            logger.error(f"Erro ao salvar mÃ©tricas: {e}")
    
    def generate_report(self, duration_minutes: int = 60) -> Dict:
        """
        Gera relatÃ³rio de mÃ©tricas do perÃ­odo.
        
        Args:
            duration_minutes: DuraÃ§Ã£o do perÃ­odo em minutos
        
        Returns:
            RelatÃ³rio consolidado
        """
        cutoff_time = datetime.now() - timedelta(minutes=duration_minutes)
        
        # Filtra histÃ³rico
        recent_metrics = [
            m for m in self.history 
            if datetime.fromisoformat(m['timestamp']) > cutoff_time
        ]
        
        if not recent_metrics:
            return {'error': 'Nenhuma mÃ©trica disponÃ­vel para o perÃ­odo'}
        
        # Calcula estatÃ­sticas
        hit_ratios = [m.get('hit_ratio', 0) for m in recent_metrics]
        response_times = [m.get('response_time_ms', 0) for m in recent_metrics]
        error_rates = [m.get('error_rate', 0) for m in recent_metrics]
        
        report = {
            'period': f"Ãšltimos {duration_minutes} minutos",
            'total_samples': len(recent_metrics),
            'hit_ratio': {
                'avg': round(sum(hit_ratios) / len(hit_ratios), 2),
                'min': min(hit_ratios),
                'max': max(hit_ratios)
            },
            'response_time': {
                'avg': round(sum(response_times) / len(response_times), 2),
                'min': min(response_times),
                'max': max(response_times)
            },
            'error_rate': {
                'avg': round(sum(error_rates) / len(error_rates), 2),
                'min': min(error_rates),
                'max': max(error_rates)
            },
            'redis_availability': {
                'available': sum(1 for m in recent_metrics if m.get('redis_available', False)),
                'total': len(recent_metrics),
                'percentage': round(
                    sum(1 for m in recent_metrics if m.get('redis_available', False)) / len(recent_metrics) * 100, 2
                )
            }
        }
        
        return report
    
    def monitor_continuous(self, save_metrics: bool = False, report_interval: int = 10):
        """
        Monitoramento contÃ­nuo de mÃ©tricas.
        
        Args:
            save_metrics: Se deve salvar mÃ©tricas em arquivo
            report_interval: Intervalo para relatÃ³rios (em ciclos)
        """
        logger.info(f"Iniciando monitoramento contÃ­nuo (intervalo: {self.interval}s)")
        
        cycle_count = 0
        
        try:
            while True:
                cycle_count += 1
                
                # Coleta mÃ©tricas
                metrics = self.collect_metrics()
                self.history.append(metrics)
                
                # Verifica alertas
                alerts = self.check_alerts(metrics)
                self.alerts.extend(alerts)
                
                # Imprime mÃ©tricas
                self.print_metrics(metrics, alerts)
                
                # Salva mÃ©tricas se solicitado
                if save_metrics and cycle_count % 10 == 0:  # A cada 10 ciclos
                    self.save_metrics(metrics)
                
                # Gera relatÃ³rio periÃ³dico
                if cycle_count % report_interval == 0:
                    report = self.generate_report()
                    print("\nðŸ“‹ RELATÃ“RIO PERIÃ“DICO:")
                    print(json.dumps(report, indent=2, ensure_ascii=False))
                
                # Limpa histÃ³rico antigo (mantÃ©m Ãºltimas 1000 entradas)
                if len(self.history) > 1000:
                    self.history = self.history[-1000:]
                
                # Aguarda prÃ³ximo ciclo
                time.sleep(self.interval)
                
        except KeyboardInterrupt:
            logger.info("Monitoramento interrompido pelo usuÃ¡rio")
            
            # Gera relatÃ³rio final
            final_report = self.generate_report()
            print("\nðŸ“‹ RELATÃ“RIO FINAL:")
            print(json.dumps(final_report, indent=2, ensure_ascii=False))
    
    def run_single_check(self):
        """
        Executa verificaÃ§Ã£o Ãºnica de mÃ©tricas.
        """
        logger.info("Executando verificaÃ§Ã£o Ãºnica de mÃ©tricas")
        
        metrics = self.collect_metrics()
        alerts = self.check_alerts(metrics)
        
        self.print_metrics(metrics, alerts)
        
        return metrics, alerts

def main():
    """FunÃ§Ã£o principal do script."""
    parser = argparse.ArgumentParser(description='Monitor de MÃ©tricas de Cache')
    parser.add_argument('--redis-url', help='URL do Redis')
    parser.add_argument('--interval', type=int, default=30, help='Intervalo de monitoramento (segundos)')
    parser.add_argument('--continuous', action='store_true', help='Monitoramento contÃ­nuo')
    parser.add_argument('--save-metrics', action='store_true', help='Salvar mÃ©tricas em arquivo')
    parser.add_argument('--report-interval', type=int, default=10, help='Intervalo para relatÃ³rios (ciclos)')
    parser.add_argument('--duration', type=int, default=60, help='DuraÃ§Ã£o para relatÃ³rios (minutos)')
    
    args = parser.parse_args()
    
    # Cria monitor
    monitor = CacheMetricsMonitor(
        redis_url=args.redis_url,
        interval=args.interval
    )
    
    if args.continuous:
        # Monitoramento contÃ­nuo
        monitor.monitor_continuous(
            save_metrics=args.save_metrics,
            report_interval=args.report_interval
        )
    else:
        # VerificaÃ§Ã£o Ãºnica
        metrics, alerts = monitor.run_single_check()
        
        # Gera relatÃ³rio se solicitado
        if args.duration > 0:
            report = monitor.generate_report(args.duration)
            print("\nðŸ“‹ RELATÃ“RIO:")
            print(json.dumps(report, indent=2, ensure_ascii=False))

if __name__ == '__main__':
    main() 