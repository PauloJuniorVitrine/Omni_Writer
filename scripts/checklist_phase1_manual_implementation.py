#!/usr/bin/env python3
"""
Script de Implementa√ß√£o Manual - Fase 1: Banco de Dados
======================================================

Implementa a migra√ß√£o completa para PostgreSQL conforme checklist.
Prompt: Implementa√ß√£o manual do checklist - Fase 1 Banco de Dados
Ruleset: enterprise_control_layer.yaml
Data/Hora: 2025-01-27T12:30:00Z
Tracing ID: CHECKLIST_PHASE1_MANUAL_20250127_001
"""

import os
import sys
import logging
import json
import time
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path

# Configura√ß√£o de logging estruturado
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s',
    handlers=[
        logging.FileHandler("logs/exec_trace/checklist_phase1_manual.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("checklist_phase1_manual")

# Tracing ID √∫nico para rastreabilidade
TRACING_ID = "CHECKLIST_PHASE1_MANUAL_20250127_001"

class ChecklistPhase1ManualImplementation:
    """
    Implementa√ß√£o manual da Fase 1 do Checklist - Banco de Dados
    
    Objetivos:
    - Preparar migra√ß√£o para PostgreSQL
    - Configurar pool de conex√µes otimizado
    - Implementar retry logic
    - Validar integridade dos dados
    """
    
    def __init__(self):
        """Inicializa a implementa√ß√£o manual da Fase 1."""
        self.tracing_id = TRACING_ID
        self.start_time = datetime.now()
        self.results = {
            "phase": "phase1_database_manual",
            "tracing_id": self.tracing_id,
            "start_time": self.start_time.isoformat(),
            "steps": [],
            "status": "in_progress"
        }
        
        # Configura√ß√µes baseadas em c√≥digo real
        self.postgres_url = os.getenv('POSTGRES_URL', 'postgresql://omniwriter:omniwriter@localhost:5432/omniwriter')
        self.sqlite_path = os.getenv('STATUS_DB_PATH', os.path.join(os.getcwd(), 'status.db'))
        self.feedback_file = os.path.join(os.path.dirname(__file__), '../feedback/feedback_data.json')
        
        logger.info(f"[{self.tracing_id}] Iniciando implementa√ß√£o manual da Fase 1 - Banco de Dados")
    
    def step_1_create_backup_scripts(self) -> bool:
        """
        Passo 1: Criar scripts de backup automatizado.
        
        Cria scripts para backup de seguran√ßa antes da migra√ß√£o.
        """
        logger.info(f"[{self.tracing_id}] Executando Passo 1: Cria√ß√£o de Scripts de Backup")
        
        try:
            # Script de backup SQLite
            backup_sqlite_script = '''#!/usr/bin/env python3
"""
Script de Backup SQLite - Omni Writer
====================================

Cria backup de seguran√ßa do banco SQLite antes da migra√ß√£o.
Prompt: Backup SQLite antes da migra√ß√£o
Ruleset: enterprise_control_layer.yaml
Data/Hora: {timestamp}
"""

import os
import shutil
import json
from datetime import datetime
from pathlib import Path

def backup_sqlite_database():
    """Cria backup do banco SQLite."""
    sqlite_path = os.getenv('STATUS_DB_PATH', 'status.db')
    
    if not os.path.exists(sqlite_path):
        print(f"‚ö†Ô∏è Banco SQLite n√£o encontrado: {{sqlite_path}}")
        return False
    
    # Criar diret√≥rio de backup
    backup_dir = Path("backups") / datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir.mkdir(parents=True, exist_ok=True)
    
    # Backup do arquivo
    backup_file = backup_dir / "status_backup.db"
    shutil.copy2(sqlite_path, backup_file)
    
    # Metadados do backup
    metadata = {{
        "backup_time": datetime.now().isoformat(),
        "original_file": sqlite_path,
        "backup_file": str(backup_file),
        "file_size": os.path.getsize(backup_file)
    }}
    
    with open(backup_dir / "backup_metadata.json", "w") as f:
        json.dump(metadata, f, indent=2)
    
    print(f"‚úÖ Backup SQLite criado: {{backup_file}}")
    return True

if __name__ == "__main__":
    backup_sqlite_database()
'''.format(timestamp=datetime.now().isoformat())
            
            with open("scripts/backup_sqlite.py", "w", encoding="utf-8") as f:
                f.write(backup_sqlite_script)
            
            # Script de backup feedback
            backup_feedback_script = '''#!/usr/bin/env python3
"""
Script de Backup Feedback - Omni Writer
======================================

Cria backup de seguran√ßa do feedback JSON antes da migra√ß√£o.
Prompt: Backup feedback antes da migra√ß√£o
Ruleset: enterprise_control_layer.yaml
Data/Hora: {timestamp}
"""

import os
import shutil
import json
from datetime import datetime
from pathlib import Path

def backup_feedback_data():
    """Cria backup do feedback JSON."""
    feedback_file = os.path.join(os.path.dirname(__file__), '../feedback/feedback_data.json')
    
    if not os.path.exists(feedback_file):
        print(f"‚ö†Ô∏è Arquivo de feedback n√£o encontrado: {{feedback_file}}")
        return False
    
    # Criar diret√≥rio de backup
    backup_dir = Path("backups") / datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_dir.mkdir(parents=True, exist_ok=True)
    
    # Backup do arquivo
    backup_file = backup_dir / "feedback_backup.json"
    shutil.copy2(feedback_file, backup_file)
    
    # Metadados do backup
    metadata = {{
        "backup_time": datetime.now().isoformat(),
        "original_file": feedback_file,
        "backup_file": str(backup_file),
        "file_size": os.path.getsize(backup_file)
    }}
    
    with open(backup_dir / "backup_metadata.json", "w") as f:
        json.dump(metadata, f, indent=2)
    
    print(f"‚úÖ Backup feedback criado: {{backup_file}}")
    return True

if __name__ == "__main__":
    backup_feedback_data()
'''.format(timestamp=datetime.now().isoformat())
            
            with open("scripts/backup_feedback.py", "w", encoding="utf-8") as f:
                f.write(backup_feedback_script)
            
            logger.info(f"[{self.tracing_id}] ‚úÖ Scripts de backup criados")
            
            self.results["steps"].append({
                "step": "create_backup_scripts",
                "status": "completed",
                "timestamp": datetime.now().isoformat(),
                "files_created": ["scripts/backup_sqlite.py", "scripts/backup_feedback.py"]
            })
            
            return True
            
        except Exception as e:
            logger.error(f"[{self.tracing_id}] ‚ùå Erro ao criar scripts de backup: {e}")
            self.results["steps"].append({
                "step": "create_backup_scripts",
                "status": "failed",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            })
            return False
    
    def step_2_create_pool_configuration(self) -> bool:
        """
        Passo 2: Criar configura√ß√£o otimizada do pool de conex√µes.
        
        Configura pool de conex√µes PostgreSQL otimizado para produ√ß√£o.
        """
        logger.info(f"[{self.tracing_id}] Executando Passo 2: Configura√ß√£o do Pool de Conex√µes")
        
        try:
            pool_config_content = '''"""
Configura√ß√£o otimizada do pool de conex√µes PostgreSQL.
Prompt: Configura√ß√£o pool de conex√µes PostgreSQL
Ruleset: enterprise_control_layer.yaml
Data/Hora: {timestamp}
"""

from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool
import os
import logging

# Configura√ß√£o de logging
logger = logging.getLogger("postgresql_pool")

# Configura√ß√µes do pool baseadas em produ√ß√£o
POSTGRESQL_POOL_CONFIG = {{
    "pool_size": 10,
    "max_overflow": 20,
    "pool_timeout": 30,
    "pool_recycle": 3600,
    "pool_pre_ping": True,
    "echo": False
}}

def create_postgresql_engine(url: str = None):
    """
    Cria engine PostgreSQL com pool otimizado.
    
    Args:
        url: URL de conex√£o PostgreSQL
        
    Returns:
        SQLAlchemy engine configurado
    """
    if url is None:
        url = os.getenv('POSTGRES_URL', 'postgresql://omniwriter:omniwriter@localhost:5432/omniwriter')
    
    try:
        engine = create_engine(
            url,
            poolclass=QueuePool,
            **POSTGRESQL_POOL_CONFIG
        )
        
        logger.info("Engine PostgreSQL criado com sucesso")
        return engine
        
    except Exception as e:
        logger.error(f"Erro ao criar engine PostgreSQL: {{e}}")
        raise

def get_connection_pool_stats(engine):
    """
    Obt√©m estat√≠sticas do pool de conex√µes.
    
    Args:
        engine: SQLAlchemy engine
        
    Returns:
        Dict com estat√≠sticas do pool
    """
    pool = engine.pool
    return {{
        "pool_size": pool.size(),
        "checked_in": pool.checkedin(),
        "checked_out": pool.checkedout(),
        "overflow": pool.overflow(),
        "invalid": pool.invalid()
    }}

def test_connection(engine):
    """
    Testa conex√£o com PostgreSQL.
    
    Args:
        engine: SQLAlchemy engine
        
    Returns:
        bool: True se conex√£o bem-sucedida
    """
    try:
        with engine.connect() as conn:
            result = conn.execute("SELECT 1")
            result.fetchone()
            logger.info("Conex√£o PostgreSQL testada com sucesso")
            return True
    except Exception as e:
        logger.error(f"Erro ao testar conex√£o PostgreSQL: {{e}}")
        return False
'''.format(timestamp=datetime.now().isoformat())
            
            with open("shared/postgresql_pool_config.py", "w", encoding="utf-8") as f:
                f.write(pool_config_content)
            
            logger.info(f"[{self.tracing_id}] ‚úÖ Configura√ß√£o do pool criada")
            
            self.results["steps"].append({
                "step": "create_pool_configuration",
                "status": "completed",
                "timestamp": datetime.now().isoformat(),
                "file_created": "shared/postgresql_pool_config.py"
            })
            
            return True
            
        except Exception as e:
            logger.error(f"[{self.tracing_id}] ‚ùå Erro ao criar configura√ß√£o do pool: {e}")
            self.results["steps"].append({
                "step": "create_pool_configuration",
                "status": "failed",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            })
            return False
    
    def step_3_create_retry_logic(self) -> bool:
        """
        Passo 3: Criar retry logic robusta.
        
        Implementa retry logic para falhas de conex√£o PostgreSQL.
        """
        logger.info(f"[{self.tracing_id}] Executando Passo 3: Implementa√ß√£o de Retry Logic")
        
        try:
            retry_logic_content = '''"""
Retry Logic para PostgreSQL - Omni Writer
========================================

Implementa retry logic robusta para falhas de conex√£o PostgreSQL.
Prompt: Retry logic para PostgreSQL
Ruleset: enterprise_control_layer.yaml
Data/Hora: {timestamp}
"""

import time
import logging
from functools import wraps
from typing import Callable, Any, Optional
from sqlalchemy.exc import OperationalError, DisconnectionError

# Configura√ß√£o de logging
logger = logging.getLogger("postgresql_retry")

# Configura√ß√µes de retry
RETRY_CONFIG = {{
    "max_attempts": 3,
    "base_delay": 1.0,
    "max_delay": 10.0,
    "backoff_factor": 2.0
}}

def exponential_backoff(attempt: int, base_delay: float = 1.0, max_delay: float = 10.0, backoff_factor: float = 2.0) -> float:
    """
    Calcula delay exponencial para retry.
    
    Args:
        attempt: N√∫mero da tentativa
        base_delay: Delay base em segundos
        max_delay: Delay m√°ximo em segundos
        backoff_factor: Fator de backoff
        
    Returns:
        Delay em segundos
    """
    delay = base_delay * (backoff_factor ** (attempt - 1))
    return min(delay, max_delay)

def postgresql_retry(max_attempts: int = None, base_delay: float = None, max_delay: float = None, backoff_factor: float = None):
    """
    Decorator para retry logic em opera√ß√µes PostgreSQL.
    
    Args:
        max_attempts: N√∫mero m√°ximo de tentativas
        base_delay: Delay base em segundos
        max_delay: Delay m√°ximo em segundos
        backoff_factor: Fator de backoff
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        def wrapper(*args, **kwargs) -> Any:
            attempts = max_attempts or RETRY_CONFIG["max_attempts"]
            base = base_delay or RETRY_CONFIG["base_delay"]
            max_d = max_delay or RETRY_CONFIG["max_delay"]
            backoff = backoff_factor or RETRY_CONFIG["backoff_factor"]
            
            last_exception = None
            
            for attempt in range(1, attempts + 1):
                try:
                    return func(*args, **kwargs)
                    
                except (OperationalError, DisconnectionError) as e:
                    last_exception = e
                    
                    if attempt == attempts:
                        logger.error(f"Falha ap√≥s {{attempts}} tentativas: {{e}}")
                        raise
                    
                    delay = exponential_backoff(attempt, base, max_d, backoff)
                    logger.warning(f"Tentativa {{attempt}} falhou, aguardando {{delay}}s: {{e}}")
                    time.sleep(delay)
                    
                except Exception as e:
                    # N√£o retry para outros tipos de erro
                    logger.error(f"Erro n√£o recuper√°vel: {{e}}")
                    raise
            
            # Nunca deve chegar aqui
            raise last_exception
            
        return wrapper
    return decorator

class PostgreSQLRetryHandler:
    """
    Handler para retry logic em opera√ß√µes PostgreSQL.
    """
    
    def __init__(self, max_attempts: int = 3, base_delay: float = 1.0, max_delay: float = 10.0):
        self.max_attempts = max_attempts
        self.base_delay = base_delay
        self.max_delay = max_delay
        self.backoff_factor = 2.0
    
    def execute_with_retry(self, operation: Callable, *args, **kwargs) -> Any:
        """
        Executa opera√ß√£o com retry logic.
        
        Args:
            operation: Fun√ß√£o a ser executada
            *args: Argumentos posicionais
            **kwargs: Argumentos nomeados
            
        Returns:
            Resultado da opera√ß√£o
        """
        last_exception = None
        
        for attempt in range(1, self.max_attempts + 1):
            try:
                return operation(*args, **kwargs)
                
            except (OperationalError, DisconnectionError) as e:
                last_exception = e
                
                if attempt == self.max_attempts:
                    logger.error(f"Falha ap√≥s {{self.max_attempts}} tentativas: {{e}}")
                    raise
                
                delay = exponential_backoff(attempt, self.base_delay, self.max_delay, self.backoff_factor)
                logger.warning(f"Tentativa {{attempt}} falhou, aguardando {{delay}}s: {{e}}")
                time.sleep(delay)
        
        raise last_exception
'''.format(timestamp=datetime.now().isoformat())
            
            with open("shared/postgresql_retry_logic.py", "w", encoding="utf-8") as f:
                f.write(retry_logic_content)
            
            logger.info(f"[{self.tracing_id}] ‚úÖ Retry logic criada")
            
            self.results["steps"].append({
                "step": "create_retry_logic",
                "status": "completed",
                "timestamp": datetime.now().isoformat(),
                "file_created": "shared/postgresql_retry_logic.py"
            })
            
            return True
            
        except Exception as e:
            logger.error(f"[{self.tracing_id}] ‚ùå Erro ao criar retry logic: {e}")
            self.results["steps"].append({
                "step": "create_retry_logic",
                "status": "failed",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            })
            return False
    
    def step_4_create_validation_scripts(self) -> bool:
        """
        Passo 4: Criar scripts de valida√ß√£o de integridade.
        
        Cria scripts para validar integridade dos dados migrados.
        """
        logger.info(f"[{self.tracing_id}] Executando Passo 4: Cria√ß√£o de Scripts de Valida√ß√£o")
        
        try:
            validation_script = '''#!/usr/bin/env python3
"""
Valida√ß√£o de Integridade - Migra√ß√£o PostgreSQL
==============================================

Valida integridade dos dados migrados para PostgreSQL.
Prompt: Valida√ß√£o integridade migra√ß√£o PostgreSQL
Ruleset: enterprise_control_layer.yaml
Data/Hora: {timestamp}
"""

import os
import sqlite3
import json
from sqlalchemy import create_engine, text
from typing import Dict, List, Any
from datetime import datetime

def validate_status_migration():
    """Valida migra√ß√£o de dados de status."""
    print("üîç Validando migra√ß√£o de status...")
    
    # Dados originais (SQLite)
    sqlite_path = os.getenv('STATUS_DB_PATH', 'status.db')
    sqlite_data = []
    
    if os.path.exists(sqlite_path):
        conn = sqlite3.connect(sqlite_path)
        cursor = conn.cursor()
        cursor.execute('SELECT trace_id, total, current, status FROM status')
        sqlite_data = cursor.fetchall()
        conn.close()
    
    # Dados migrados (PostgreSQL)
    postgres_url = os.getenv('POSTGRES_URL', 'postgresql://omniwriter:omniwriter@localhost:5432/omniwriter')
    engine = create_engine(postgres_url)
    
    with engine.connect() as conn:
        result = conn.execute(text('SELECT trace_id, total, current, status FROM status'))
        postgres_data = result.fetchall()
    
    # Compara√ß√£o
    sqlite_count = len(sqlite_data)
    postgres_count = len(postgres_data)
    
    print(f"üìä SQLite: {{sqlite_count}} registros")
    print(f"üìä PostgreSQL: {{postgres_count}} registros")
    
    if sqlite_count == postgres_count:
        print("‚úÖ Contagem de registros igual")
    else:
        print("‚ùå Contagem de registros diferente")
        return False
    
    # Validar dados espec√≠ficos
    sqlite_dict = {{row[0]: row[1:] for row in sqlite_data}}
    postgres_dict = {{row[0]: row[1:] for row in postgres_data}}
    
    for trace_id in sqlite_dict:
        if trace_id not in postgres_dict:
            print(f"‚ùå Trace ID {{trace_id}} n√£o encontrado no PostgreSQL")
            return False
        
        if sqlite_dict[trace_id] != postgres_dict[trace_id]:
            print(f"‚ùå Dados diferentes para trace_id {{trace_id}}")
            return False
    
    print("‚úÖ Valida√ß√£o de status conclu√≠da com sucesso")
    return True

def validate_feedback_migration():
    """Valida migra√ß√£o de dados de feedback."""
    print("üîç Validando migra√ß√£o de feedback...")
    
    # Dados originais (JSON)
    feedback_file = os.path.join(os.path.dirname(__file__), '../feedback/feedback_data.json')
    json_data = []
    
    if os.path.exists(feedback_file):
        with open(feedback_file, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
    
    # Dados migrados (PostgreSQL)
    postgres_url = os.getenv('POSTGRES_URL', 'postgresql://omniwriter:omniwriter@localhost:5432/omniwriter')
    engine = create_engine(postgres_url)
    
    with engine.connect() as conn:
        result = conn.execute(text('SELECT trace_id, feedback_data FROM feedback'))
        postgres_data = result.fetchall()
    
    # Compara√ß√£o
    json_count = len(json_data)
    postgres_count = len(postgres_data)
    
    print(f"üìä JSON: {{json_count}} registros")
    print(f"üìä PostgreSQL: {{postgres_count}} registros")
    
    if json_count == postgres_count:
        print("‚úÖ Contagem de registros igual")
    else:
        print("‚ùå Contagem de registros diferente")
        return False
    
    print("‚úÖ Valida√ß√£o de feedback conclu√≠da com sucesso")
    return True

def main():
    """Executa valida√ß√£o completa."""
    print("üöÄ Iniciando valida√ß√£o de integridade...")
    
    status_ok = validate_status_migration()
    feedback_ok = validate_feedback_migration()
    
    if status_ok and feedback_ok:
        print("‚úÖ Valida√ß√£o completa: TODOS OS DADOS MIGRADOS CORRETAMENTE")
        return True
    else:
        print("‚ùå Valida√ß√£o falhou: VERIFICAR MIGRA√á√ÉO")
        return False

if __name__ == "__main__":
    main()
'''.format(timestamp=datetime.now().isoformat())
            
            with open("scripts/validate_migration_integrity.py", "w", encoding="utf-8") as f:
                f.write(validation_script)
            
            logger.info(f"[{self.tracing_id}] ‚úÖ Script de valida√ß√£o criado")
            
            self.results["steps"].append({
                "step": "create_validation_scripts",
                "status": "completed",
                "timestamp": datetime.now().isoformat(),
                "file_created": "scripts/validate_migration_integrity.py"
            })
            
            return True
            
        except Exception as e:
            logger.error(f"[{self.tracing_id}] ‚ùå Erro ao criar script de valida√ß√£o: {e}")
            self.results["steps"].append({
                "step": "create_validation_scripts",
                "status": "failed",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            })
            return False
    
    def step_5_update_configurations(self) -> bool:
        """
        Passo 5: Atualizar configura√ß√µes para PostgreSQL.
        
        Atualiza configura√ß√µes para priorizar PostgreSQL.
        """
        logger.info(f"[{self.tracing_id}] Executando Passo 5: Atualiza√ß√£o de Configura√ß√µes")
        
        try:
            # Criar arquivo .env.example atualizado
            env_example = '''# Configura√ß√µes de Banco de Dados - Produ√ß√£o
POSTGRES_URL=postgresql://omniwriter:omniwriter@localhost:5432/omniwriter
REDIS_URL=redis://localhost:6379/0

# Storage Distribu√≠do
ENABLE_DISTRIBUTED_STORAGE=true
STORAGE_FALLBACK=postgresql

# Pool de Conex√µes
POSTGRES_POOL_SIZE=10
POSTGRES_MAX_OVERFLOW=20
POSTGRES_POOL_TIMEOUT=30

# Retry Logic
DB_RETRY_ATTEMPTS=3
DB_RETRY_DELAY=1.0

# Configura√ß√µes de Produ√ß√£o
ENVIRONMENT=production
DEBUG=false

# Configura√ß√µes de Monitoramento
PROMETHEUS_ENABLED=true
SENTRY_DSN=your_sentry_dsn_here

# Configura√ß√µes de Cache
CACHE_TTL=3600
STORAGE_MAX_RETRIES=3
'''
            
            with open(".env.example", "w", encoding="utf-8") as f:
                f.write(env_example)
            
            # Criar arquivo de configura√ß√£o de produ√ß√£o
            production_config = '''"""
Configura√ß√£o de Produ√ß√£o - Omni Writer
======================================

Configura√ß√µes otimizadas para ambiente de produ√ß√£o.
Prompt: Configura√ß√£o de produ√ß√£o PostgreSQL
Ruleset: enterprise_control_layer.yaml
Data/Hora: {timestamp}
"""

import os
from shared.constants import DatabaseConstants, StorageConstants

# ============================================================================
# CONFIGURA√á√ïES DE BANCO DE DADOS - PRODU√á√ÉO
# ============================================================================

# URL do PostgreSQL (prioridade para produ√ß√£o)
POSTGRESQL_CONNECTION_URL = os.getenv('POSTGRES_URL', DatabaseConstants.POSTGRESQL_DEFAULT_URL)

# URL do Redis
REDIS_CONNECTION_URL = os.getenv('REDIS_URL', DatabaseConstants.REDIS_DEFAULT_URL)

# Habilitar storage distribu√≠do por padr√£o
DISTRIBUTED_STORAGE_ENABLED = os.getenv(
    'ENABLE_DISTRIBUTED_STORAGE', 
    'true'  # Habilitado por padr√£o em produ√ß√£o
).lower() == 'true'

# PostgreSQL como storage padr√£o
STORAGE_FALLBACK_TYPE = os.getenv('STORAGE_FALLBACK', 'postgresql').lower()

# ============================================================================
# CONFIGURA√á√ïES DE POOL DE CONEX√ïES
# ============================================================================

# Tamanho do pool de conex√µes
POSTGRESQL_POOL_SIZE = int(os.getenv('POSTGRES_POOL_SIZE', '10'))

# Overflow m√°ximo do pool
POSTGRESQL_MAX_OVERFLOW = int(os.getenv('POSTGRES_MAX_OVERFLOW', '20'))

# Timeout do pool
POSTGRESQL_POOL_TIMEOUT = int(os.getenv('POSTGRES_POOL_TIMEOUT', '30'))

# ============================================================================
# CONFIGURA√á√ïES DE RETRY
# ============================================================================

# N√∫mero de tentativas de retry
DB_RETRY_ATTEMPTS = int(os.getenv('DB_RETRY_ATTEMPTS', '3'))

# Delay entre tentativas
DB_RETRY_DELAY = float(os.getenv('DB_RETRY_DELAY', '1.0'))

# ============================================================================
# CONFIGURA√á√ïES DE MONITORAMENTO
# ============================================================================

# Habilitar Prometheus
PROMETHEUS_ENABLED = os.getenv('PROMETHEUS_ENABLED', 'true').lower() == 'true'

# DSN do Sentry
SENTRY_DSN = os.getenv('SENTRY_DSN', None)

# ============================================================================
# CONFIGURA√á√ïES DE CACHE
# ============================================================================

# TTL do cache em segundos
CACHE_TTL = int(os.getenv('CACHE_TTL', '3600'))

# N√∫mero m√°ximo de tentativas de storage
STORAGE_MAX_RETRIES = int(os.getenv('STORAGE_MAX_RETRIES', '3'))
'''.format(timestamp=datetime.now().isoformat())
            
            with open("shared/production_config.py", "w", encoding="utf-8") as f:
                f.write(production_config)
            
            logger.info(f"[{self.tracing_id}] ‚úÖ Configura√ß√µes atualizadas")
            
            self.results["steps"].append({
                "step": "update_configurations",
                "status": "completed",
                "timestamp": datetime.now().isoformat(),
                "files_created": [".env.example", "shared/production_config.py"]
            })
            
            return True
            
        except Exception as e:
            logger.error(f"[{self.tracing_id}] ‚ùå Erro ao atualizar configura√ß√µes: {e}")
            self.results["steps"].append({
                "step": "update_configurations",
                "status": "failed",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            })
            return False
    
    def step_6_create_deployment_guide(self) -> bool:
        """
        Passo 6: Criar guia de deploy para produ√ß√£o.
        
        Cria documenta√ß√£o para deploy em produ√ß√£o.
        """
        logger.info(f"[{self.tracing_id}] Executando Passo 6: Cria√ß√£o do Guia de Deploy")
        
        try:
            deployment_guide = '''# üöÄ GUIA DE DEPLOY - FASE 1: BANCO DE DADOS

## **üìã RESUMO**
Este guia documenta o deploy da Fase 1 do checklist: migra√ß√£o completa para PostgreSQL.

## **üéØ OBJETIVOS**
- ‚úÖ Migra√ß√£o completa para PostgreSQL
- ‚úÖ Pool de conex√µes otimizado
- ‚úÖ Retry logic robusta
- ‚úÖ Valida√ß√£o de integridade

## **üîß PR√â-REQUISITOS**

### **1. Ambiente**
- Docker e Docker Compose instalados
- Python 3.8+ configurado
- PostgreSQL 15+ dispon√≠vel
- Redis 7+ dispon√≠vel

### **2. Configura√ß√µes**
```bash
# Copiar arquivo de exemplo
cp .env.example .env

# Editar configura√ß√µes
nano .env
```

### **3. Depend√™ncias**
```bash
# Instalar depend√™ncias Python
pip install -r requirements.txt

# Verificar PostgreSQL driver
pip install psycopg2-binary
```

## **üöÄ PASSOS DE DEPLOY**

### **Passo 1: Backup dos Dados Existentes**
```bash
# Backup SQLite
python scripts/backup_sqlite.py

# Backup feedback
python scripts/backup_feedback.py
```

### **Passo 2: Iniciar Infraestrutura**
```bash
# Iniciar PostgreSQL e Redis
docker compose up -d postgres redis

# Verificar status
docker compose ps
```

### **Passo 3: Executar Migra√ß√µes**
```bash
# Migrar status SQLite ‚Üí PostgreSQL
python scripts/migrate_status_sqlite_to_postgres.py

# Migrar feedback JSON ‚Üí PostgreSQL
python scripts/migrate_feedback_json_to_postgres.py
```

### **Passo 4: Validar Integridade**
```bash
# Validar migra√ß√£o
python scripts/validate_migration_integrity.py
```

### **Passo 5: Iniciar Aplica√ß√£o**
```bash
# Iniciar aplica√ß√£o completa
docker compose up -d

# Verificar logs
docker compose logs -f app
```

## **üìä VALIDA√á√ÉO**

### **1. Testes de Integra√ß√£o**
```bash
# Executar testes PostgreSQL
pytest tests/integration/test_postgresql.py -v
```

### **2. Verificar M√©tricas**
- Acessar Prometheus: http://localhost:9090
- Acessar Grafana: http://localhost:3000
- Verificar logs: `logs/exec_trace/`

### **3. Testar Funcionalidades**
- Gerar artigo via API
- Verificar persist√™ncia no PostgreSQL
- Validar cache no Redis

## **üîç TROUBLESHOOTING**

### **Problema: Conex√£o PostgreSQL falha**
```bash
# Verificar se PostgreSQL est√° rodando
docker compose ps postgres

# Verificar logs
docker compose logs postgres

# Testar conex√£o manual
psql -h localhost -U omniwriter -d omniwriter
```

### **Problema: Migra√ß√£o falha**
```bash
# Verificar backup
ls -la backups/

# Restaurar backup se necess√°rio
cp backups/YYYYMMDD_HHMMSS/status_backup.db status.db
```

### **Problema: Performance ruim**
```bash
# Verificar pool de conex√µes
python -c "from shared.postgresql_pool_config import get_connection_pool_stats; print(get_connection_pool_stats(engine))"

# Ajustar configura√ß√µes no .env
POSTGRES_POOL_SIZE=20
POSTGRES_MAX_OVERFLOW=30
```

## **üìà M√âTRICAS DE SUCESSO**

| M√©trica | Meta | Como Medir |
|---------|------|------------|
| **Tempo de Resposta** | < 100ms | Prometheus / Grafana |
| **Uptime** | > 99.9% | Monitoramento |
| **Cobertura de Testes** | > 85% | pytest --cov |
| **Integridade de Dados** | 100% | Script de valida√ß√£o |

## **üîÑ ROLLBACK**

### **Se necess√°rio reverter:**
```bash
# Parar aplica√ß√£o
docker compose down

# Restaurar SQLite
cp backups/YYYYMMDD_HHMMSS/status_backup.db status.db

# Restaurar feedback
cp backups/YYYYMMDD_HHMMSS/feedback_backup.json feedback/feedback_data.json

# Reiniciar com configura√ß√£o anterior
docker compose up -d
```

## **üìû SUPORTE**

- **Logs**: `logs/exec_trace/checklist_phase1_manual.log`
- **Documenta√ß√£o**: `docs/checklist_phase1_implementation_report.md`
- **Issues**: Criar issue no reposit√≥rio

---

**Data de Cria√ß√£o**: {timestamp}  
**Tracing ID**: {tracing_id}  
**Status**: ‚úÖ Implementado
'''.format(timestamp=datetime.now().isoformat(), tracing_id=self.tracing_id)
            
            with open("docs/deployment_guide_phase1.md", "w", encoding="utf-8") as f:
                f.write(deployment_guide)
            
            logger.info(f"[{self.tracing_id}] ‚úÖ Guia de deploy criado")
            
            self.results["steps"].append({
                "step": "create_deployment_guide",
                "status": "completed",
                "timestamp": datetime.now().isoformat(),
                "file_created": "docs/deployment_guide_phase1.md"
            })
            
            return True
            
        except Exception as e:
            logger.error(f"[{self.tracing_id}] ‚ùå Erro ao criar guia de deploy: {e}")
            self.results["steps"].append({
                "step": "create_deployment_guide",
                "status": "failed",
                "timestamp": datetime.now().isoformat(),
                "error": str(e)
            })
            return False
    
    def execute_all_steps(self) -> bool:
        """
        Executa todos os passos da implementa√ß√£o manual.
        
        Returns:
            bool: True se todos os passos foram executados com sucesso
        """
        logger.info(f"[{self.tracing_id}] Iniciando execu√ß√£o de todos os passos")
        
        steps = [
            ("step_1_create_backup_scripts", self.step_1_create_backup_scripts),
            ("step_2_create_pool_configuration", self.step_2_create_pool_configuration),
            ("step_3_create_retry_logic", self.step_3_create_retry_logic),
            ("step_4_create_validation_scripts", self.step_4_create_validation_scripts),
            ("step_5_update_configurations", self.step_5_update_configurations),
            ("step_6_create_deployment_guide", self.step_6_create_deployment_guide)
        ]
        
        success_count = 0
        total_steps = len(steps)
        
        for step_name, step_func in steps:
            logger.info(f"[{self.tracing_id}] Executando {step_name}")
            
            try:
                if step_func():
                    success_count += 1
                    logger.info(f"[{self.tracing_id}] ‚úÖ {step_name} conclu√≠do com sucesso")
                else:
                    logger.error(f"[{self.tracing_id}] ‚ùå {step_name} falhou")
                    
            except Exception as e:
                logger.error(f"[{self.tracing_id}] ‚ùå Erro em {step_name}: {e}")
        
        # Atualizar resultados finais
        self.results["end_time"] = datetime.now().isoformat()
        self.results["success_count"] = success_count
        self.results["total_steps"] = total_steps
        
        if success_count == total_steps:
            self.results["status"] = "completed"
            logger.info(f"[{self.tracing_id}] ‚úÖ Todos os {total_steps} passos executados com sucesso")
        else:
            self.results["status"] = "partial"
            logger.warning(f"[{self.tracing_id}] ‚ö†Ô∏è {success_count}/{total_steps} passos executados com sucesso")
        
        # Salvar resultados
        results_file = f"logs/exec_trace/checklist_phase1_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(results_file, "w", encoding="utf-8") as f:
            json.dump(self.results, f, indent=2, default=str)
        
        logger.info(f"[{self.tracing_id}] üìä Resultados salvos em: {results_file}")
        
        return success_count == total_steps

def main():
    """Fun√ß√£o principal."""
    print("üöÄ Iniciando implementa√ß√£o manual da Fase 1 - Banco de Dados")
    print("=" * 60)
    
    implementation = ChecklistPhase1ManualImplementation()
    
    try:
        success = implementation.execute_all_steps()
        
        if success:
            print("‚úÖ Implementa√ß√£o manual conclu√≠da com sucesso!")
            print("üìã Pr√≥ximos passos:")
            print("   1. Configurar ambiente Python")
            print("   2. Executar scripts de backup")
            print("   3. Iniciar PostgreSQL e Redis")
            print("   4. Executar migra√ß√µes")
            print("   5. Validar integridade")
            print("   6. Testar aplica√ß√£o")
        else:
            print("‚ö†Ô∏è Implementa√ß√£o parcial - verificar logs")
            
    except Exception as e:
        print(f"‚ùå Erro na implementa√ß√£o: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 