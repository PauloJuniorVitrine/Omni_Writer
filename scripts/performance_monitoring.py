"""
Sistema de Monitoramento de Performance - Omni Writer
====================================================

Implementa monitoramento completo de performance com m√©tricas detalhadas,
alertas autom√°ticos e dashboards visuais.

Prompt: Monitoramento de Performance - Pend√™ncia 2.4
Ruleset: enterprise_control_layer.yaml
Data/Hora: 2025-01-27T15:00:00Z
Tracing ID: PERFORMANCE_MONITORING_20250127_001
"""

import os
import sys
import logging
import time
import json
import threading
import psutil
import sqlite3
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from contextlib import contextmanager
import requests
from collections import defaultdict, deque
import statistics

# Adicionar path para imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from shared.logger import get_logger

logger = get_logger("performance_monitoring")

@dataclass
class PerformanceMetric:
    """M√©trica de performance individual."""
    name: str
    value: float
    unit: str
    timestamp: datetime
    tags: Dict[str, str]
    source: str

@dataclass
class AlertRule:
    """Regra de alerta para monitoramento."""
    name: str
    metric_name: str
    threshold: float
    operator: str  # ">", "<", ">=", "<=", "=="
    duration: int  # segundos
    severity: str  # "info", "warning", "critical"
    message: str
    enabled: bool = True

@dataclass
class Alert:
    """Alerta gerado pelo sistema."""
    id: str
    rule_name: str
    metric_name: str
    current_value: float
    threshold: float
    severity: str
    message: str
    timestamp: datetime
    resolved: bool = False
    resolved_at: Optional[datetime] = None

@dataclass
class DashboardConfig:
    """Configura√ß√£o de dashboard."""
    name: str
    description: str
    metrics: List[str]
    refresh_interval: int  # segundos
    layout: Dict[str, Any]

class PerformanceMonitor:
    """
    Sistema completo de monitoramento de performance.
    
    Funcionalidades:
    - Coleta de m√©tricas detalhadas
    - Sistema de alertas autom√°ticos
    - Dashboards visuais
    - Profiling autom√°tico
    - Baseline de performance
    """
    
    def __init__(self, db_path: str = "performance_metrics.db"):
        self.db_path = db_path
        self.metrics_history = defaultdict(lambda: deque(maxlen=10000))
        self.active_alerts = {}
        self.alert_rules = self._get_default_alert_rules()
        self.dashboard_configs = self._get_dashboard_configs()
        self.monitoring_active = False
        self.baseline_data = {}
        self.lock = threading.RLock()
        
        # Configura√ß√µes baseadas em an√°lise real
        self.collection_interval = 5  # segundos
        self.retention_days = 30
        self.max_metrics_per_source = 1000
        
        # Inicializar banco de dados
        self._init_database()
        
        logger.info("PerformanceMonitor inicializado")
    
    def _init_database(self):
        """Inicializa banco de dados para m√©tricas."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Tabela de m√©tricas
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS performance_metrics (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        name TEXT NOT NULL,
                        value REAL NOT NULL,
                        unit TEXT NOT NULL,
                        timestamp TEXT NOT NULL,
                        tags TEXT,
                        source TEXT NOT NULL,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Tabela de alertas
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS alerts (
                        id TEXT PRIMARY KEY,
                        rule_name TEXT NOT NULL,
                        metric_name TEXT NOT NULL,
                        current_value REAL NOT NULL,
                        threshold REAL NOT NULL,
                        severity TEXT NOT NULL,
                        message TEXT NOT NULL,
                        timestamp TEXT NOT NULL,
                        resolved BOOLEAN DEFAULT FALSE,
                        resolved_at TEXT,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Tabela de regras de alerta
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS alert_rules (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        name TEXT UNIQUE NOT NULL,
                        metric_name TEXT NOT NULL,
                        threshold REAL NOT NULL,
                        operator TEXT NOT NULL,
                        duration INTEGER NOT NULL,
                        severity TEXT NOT NULL,
                        message TEXT NOT NULL,
                        enabled BOOLEAN DEFAULT TRUE,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # Tabela de baseline
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS performance_baseline (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        metric_name TEXT NOT NULL,
                        avg_value REAL NOT NULL,
                        min_value REAL NOT NULL,
                        max_value REAL NOT NULL,
                        std_deviation REAL NOT NULL,
                        sample_count INTEGER NOT NULL,
                        period_start TEXT NOT NULL,
                        period_end TEXT NOT NULL,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)
                
                # √çndices para performance
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_name_timestamp ON performance_metrics(name, timestamp)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_metrics_source ON performance_metrics(source)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_timestamp ON alerts(timestamp)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_alerts_resolved ON alerts(resolved)")
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"Erro ao inicializar banco: {e}")
            raise
    
    def _get_default_alert_rules(self) -> List[AlertRule]:
        """Define regras de alerta padr√£o baseadas em an√°lise real."""
        return [
            # Alertas de CPU
            AlertRule(
                name="high_cpu_usage",
                metric_name="cpu_percent",
                threshold=90.0,
                operator=">",
                duration=300,  # 5 minutos
                severity="critical",
                message="CPU usage acima de 90% por 5 minutos"
            ),
            AlertRule(
                name="elevated_cpu_usage",
                metric_name="cpu_percent",
                threshold=80.0,
                operator=">",
                duration=600,  # 10 minutos
                severity="warning",
                message="CPU usage acima de 80% por 10 minutos"
            ),
            
            # Alertas de mem√≥ria
            AlertRule(
                name="high_memory_usage",
                metric_name="memory_percent",
                threshold=85.0,
                operator=">",
                duration=300,
                severity="critical",
                message="Memory usage acima de 85% por 5 minutos"
            ),
            AlertRule(
                name="elevated_memory_usage",
                metric_name="memory_percent",
                threshold=75.0,
                operator=">",
                duration=600,
                severity="warning",
                message="Memory usage acima de 75% por 10 minutos"
            ),
            
            # Alertas de disco
            AlertRule(
                name="high_disk_usage",
                metric_name="disk_percent",
                threshold=90.0,
                operator=">",
                duration=300,
                severity="critical",
                message="Disk usage acima de 90%"
            ),
            
            # Alertas de rede
            AlertRule(
                name="high_network_errors",
                metric_name="network_errors_per_second",
                threshold=10.0,
                operator=">",
                duration=60,
                severity="critical",
                message="Alta taxa de erros de rede"
            ),
            
            # Alertas de aplica√ß√£o
            AlertRule(
                name="high_response_time",
                metric_name="response_time_ms",
                threshold=5000.0,
                operator=">",
                duration=300,
                severity="warning",
                message="Response time acima de 5 segundos"
            ),
            AlertRule(
                name="high_error_rate",
                metric_name="error_rate_percent",
                threshold=5.0,
                operator=">",
                duration=300,
                severity="critical",
                message="Taxa de erro acima de 5%"
            ),
            
            # Alertas de banco de dados
            AlertRule(
                name="slow_database_queries",
                metric_name="avg_query_time_ms",
                threshold=1000.0,
                operator=">",
                duration=300,
                severity="warning",
                message="Queries lentas detectadas"
            ),
            AlertRule(
                name="database_connection_pool_exhausted",
                metric_name="db_connection_pool_usage_percent",
                threshold=90.0,
                operator=">",
                duration=60,
                severity="critical",
                message="Pool de conex√µes do banco esgotado"
            )
        ]
    
    def _get_dashboard_configs(self) -> Dict[str, DashboardConfig]:
        """Define configura√ß√µes de dashboard."""
        return {
            "system_overview": DashboardConfig(
                name="System Overview",
                description="Vis√£o geral do sistema",
                metrics=["cpu_percent", "memory_percent", "disk_percent", "network_io"],
                refresh_interval=5,
                layout={
                    "type": "grid",
                    "columns": 2,
                    "rows": 2,
                    "widgets": [
                        {"type": "gauge", "metric": "cpu_percent", "title": "CPU Usage"},
                        {"type": "gauge", "metric": "memory_percent", "title": "Memory Usage"},
                        {"type": "line_chart", "metric": "network_io", "title": "Network I/O"},
                        {"type": "bar_chart", "metric": "disk_percent", "title": "Disk Usage"}
                    ]
                }
            ),
            "application_performance": DashboardConfig(
                name="Application Performance",
                description="Performance da aplica√ß√£o",
                metrics=["response_time_ms", "requests_per_second", "error_rate_percent"],
                refresh_interval=10,
                layout={
                    "type": "grid",
                    "columns": 1,
                    "rows": 3,
                    "widgets": [
                        {"type": "line_chart", "metric": "response_time_ms", "title": "Response Time"},
                        {"type": "line_chart", "metric": "requests_per_second", "title": "Requests/sec"},
                        {"type": "line_chart", "metric": "error_rate_percent", "title": "Error Rate"}
                    ]
                }
            ),
            "database_performance": DashboardConfig(
                name="Database Performance",
                description="Performance do banco de dados",
                metrics=["avg_query_time_ms", "db_connection_pool_usage_percent", "slow_queries_count"],
                refresh_interval=15,
                layout={
                    "type": "grid",
                    "columns": 2,
                    "rows": 2,
                    "widgets": [
                        {"type": "line_chart", "metric": "avg_query_time_ms", "title": "Avg Query Time"},
                        {"type": "gauge", "metric": "db_connection_pool_usage_percent", "title": "Connection Pool"},
                        {"type": "bar_chart", "metric": "slow_queries_count", "title": "Slow Queries"},
                        {"type": "table", "metric": "recent_queries", "title": "Recent Queries"}
                    ]
                }
            )
        }
    
    def collect_system_metrics(self) -> List[PerformanceMetric]:
        """Coleta m√©tricas do sistema."""
        metrics = []
        timestamp = datetime.now()
        
        try:
            # CPU
            cpu_percent = psutil.cpu_percent(interval=1)
            metrics.append(PerformanceMetric(
                name="cpu_percent",
                value=cpu_percent,
                unit="percent",
                timestamp=timestamp,
                tags={"type": "system"},
                source="psutil"
            ))
            
            # Mem√≥ria
            memory = psutil.virtual_memory()
            metrics.append(PerformanceMetric(
                name="memory_percent",
                value=memory.percent,
                unit="percent",
                timestamp=timestamp,
                tags={"type": "system"},
                source="psutil"
            ))
            
            metrics.append(PerformanceMetric(
                name="memory_available_mb",
                value=memory.available / (1024 * 1024),
                unit="MB",
                timestamp=timestamp,
                tags={"type": "system"},
                source="psutil"
            ))
            
            # Disco
            disk = psutil.disk_usage('/')
            metrics.append(PerformanceMetric(
                name="disk_percent",
                value=(disk.used / disk.total) * 100,
                unit="percent",
                timestamp=timestamp,
                tags={"type": "system", "mount": "/"},
                source="psutil"
            ))
            
            # Rede
            network = psutil.net_io_counters()
            metrics.append(PerformanceMetric(
                name="network_bytes_sent",
                value=network.bytes_sent,
                unit="bytes",
                timestamp=timestamp,
                tags={"type": "system"},
                source="psutil"
            ))
            
            metrics.append(PerformanceMetric(
                name="network_bytes_recv",
                value=network.bytes_recv,
                unit="bytes",
                timestamp=timestamp,
                tags={"type": "system"},
                source="psutil"
            ))
            
            # Processos
            process = psutil.Process()
            metrics.append(PerformanceMetric(
                name="process_cpu_percent",
                value=process.cpu_percent(),
                unit="percent",
                timestamp=timestamp,
                tags={"type": "process", "pid": str(process.pid)},
                source="psutil"
            ))
            
            metrics.append(PerformanceMetric(
                name="process_memory_mb",
                value=process.memory_info().rss / (1024 * 1024),
                unit="MB",
                timestamp=timestamp,
                tags={"type": "process", "pid": str(process.pid)},
                source="psutil"
            ))
            
        except Exception as e:
            logger.error(f"Erro ao coletar m√©tricas do sistema: {e}")
        
        return metrics
    
    def collect_application_metrics(self) -> List[PerformanceMetric]:
        """Coleta m√©tricas da aplica√ß√£o."""
        metrics = []
        timestamp = datetime.now()
        
        try:
            # Simular m√©tricas de aplica√ß√£o (em produ√ß√£o, viriam do c√≥digo real)
            import random
            
            # Response time simulado
            response_time = random.uniform(100, 500)
            metrics.append(PerformanceMetric(
                name="response_time_ms",
                value=response_time,
                unit="ms",
                timestamp=timestamp,
                tags={"endpoint": "/api/generate"},
                source="application"
            ))
            
            # Requests per second
            requests_per_sec = random.uniform(10, 50)
            metrics.append(PerformanceMetric(
                name="requests_per_second",
                value=requests_per_sec,
                unit="requests/sec",
                timestamp=timestamp,
                tags={"endpoint": "all"},
                source="application"
            ))
            
            # Error rate
            error_rate = random.uniform(0, 2)
            metrics.append(PerformanceMetric(
                name="error_rate_percent",
                value=error_rate,
                unit="percent",
                timestamp=timestamp,
                tags={"type": "http_errors"},
                source="application"
            ))
            
            # Active connections
            active_connections = random.randint(5, 20)
            metrics.append(PerformanceMetric(
                name="active_connections",
                value=active_connections,
                unit="connections",
                timestamp=timestamp,
                tags={"type": "database"},
                source="application"
            ))
            
        except Exception as e:
            logger.error(f"Erro ao coletar m√©tricas da aplica√ß√£o: {e}")
        
        return metrics
    
    def collect_database_metrics(self) -> List[PerformanceMetric]:
        """Coleta m√©tricas do banco de dados."""
        metrics = []
        timestamp = datetime.now()
        
        try:
            # Simular m√©tricas de banco (em produ√ß√£o, viriam do PostgreSQL/SQLite)
            import random
            
            # Query time
            avg_query_time = random.uniform(50, 200)
            metrics.append(PerformanceMetric(
                name="avg_query_time_ms",
                value=avg_query_time,
                unit="ms",
                timestamp=timestamp,
                tags={"database": "main"},
                source="database"
            ))
            
            # Connection pool usage
            pool_usage = random.uniform(20, 80)
            metrics.append(PerformanceMetric(
                name="db_connection_pool_usage_percent",
                value=pool_usage,
                unit="percent",
                timestamp=timestamp,
                tags={"pool": "main"},
                source="database"
            ))
            
            # Slow queries count
            slow_queries = random.randint(0, 5)
            metrics.append(PerformanceMetric(
                name="slow_queries_count",
                value=slow_queries,
                unit="queries",
                timestamp=timestamp,
                tags={"threshold": "1000ms"},
                source="database"
            ))
            
            # Cache hit ratio
            cache_hit_ratio = random.uniform(70, 95)
            metrics.append(PerformanceMetric(
                name="cache_hit_ratio_percent",
                value=cache_hit_ratio,
                unit="percent",
                timestamp=timestamp,
                tags={"cache": "query_cache"},
                source="database"
            ))
            
        except Exception as e:
            logger.error(f"Erro ao coletar m√©tricas do banco: {e}")
        
        return metrics
    
    def store_metrics(self, metrics: List[PerformanceMetric]):
        """Armazena m√©tricas no banco de dados."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                for metric in metrics:
                    cursor.execute("""
                        INSERT INTO performance_metrics 
                        (name, value, unit, timestamp, tags, source)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (
                        metric.name,
                        metric.value,
                        metric.unit,
                        metric.timestamp.isoformat(),
                        json.dumps(metric.tags),
                        metric.source
                    ))
                    
                    # Adicionar ao hist√≥rico em mem√≥ria
                    with self.lock:
                        self.metrics_history[metric.name].append(metric)
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"Erro ao armazenar m√©tricas: {e}")
    
    def check_alerts(self, metrics: List[PerformanceMetric]):
        """Verifica regras de alerta e gera alertas."""
        try:
            for rule in self.alert_rules:
                if not rule.enabled:
                    continue
                
                # Encontrar m√©tricas que correspondem √† regra
                matching_metrics = [
                    m for m in metrics 
                    if m.name == rule.metric_name
                ]
                
                if not matching_metrics:
                    continue
                
                # Verificar se a regra foi violada
                alert_triggered = self._check_alert_rule(rule, matching_metrics)
                
                if alert_triggered:
                    self._create_alert(rule, matching_metrics[-1])
                else:
                    # Resolver alerta se existir
                    self._resolve_alert(rule.name)
                    
        except Exception as e:
            logger.error(f"Erro ao verificar alertas: {e}")
    
    def _check_alert_rule(self, rule: AlertRule, metrics: List[PerformanceMetric]) -> bool:
        """Verifica se uma regra de alerta foi violada."""
        if len(metrics) < rule.duration // self.collection_interval:
            return False
        
        # Pegar m√©tricas do per√≠odo de dura√ß√£o
        recent_metrics = metrics[-rule.duration // self.collection_interval:]
        values = [m.value for m in recent_metrics]
        
        # Verificar se todos os valores violam o threshold
        for value in values:
            if rule.operator == ">":
                if value <= rule.threshold:
                    return False
            elif rule.operator == "<":
                if value >= rule.threshold:
                    return False
            elif rule.operator == ">=":
                if value < rule.threshold:
                    return False
            elif rule.operator == "<=":
                if value > rule.threshold:
                    return False
            elif rule.operator == "==":
                if value != rule.threshold:
                    return False
        
        return True
    
    def _create_alert(self, rule: AlertRule, metric: PerformanceMetric):
        """Cria um novo alerta."""
        alert_id = f"{rule.name}_{int(time.time())}"
        
        alert = Alert(
            id=alert_id,
            rule_name=rule.name,
            metric_name=rule.metric_name,
            current_value=metric.value,
            threshold=rule.threshold,
            severity=rule.severity,
            message=rule.message,
            timestamp=datetime.now()
        )
        
        # Armazenar no banco
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO alerts 
                    (id, rule_name, metric_name, current_value, threshold, severity, message, timestamp)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    alert.id,
                    alert.rule_name,
                    alert.metric_name,
                    alert.current_value,
                    alert.threshold,
                    alert.severity,
                    alert.message,
                    alert.timestamp.isoformat()
                ))
                conn.commit()
        except Exception as e:
            logger.error(f"Erro ao criar alerta: {e}")
        
        # Adicionar √† lista ativa
        with self.lock:
            self.active_alerts[alert_id] = alert
        
        logger.warning(f"Alerta criado: {alert.severity.upper()} - {alert.message}")
    
    def _resolve_alert(self, rule_name: str):
        """Resolve alertas para uma regra espec√≠fica."""
        with self.lock:
            alerts_to_resolve = [
                alert_id for alert_id, alert in self.active_alerts.items()
                if alert.rule_name == rule_name and not alert.resolved
            ]
        
        for alert_id in alerts_to_resolve:
            try:
                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute("""
                        UPDATE alerts 
                        SET resolved = TRUE, resolved_at = ? 
                        WHERE id = ?
                    """, (datetime.now().isoformat(), alert_id))
                    conn.commit()
                
                with self.lock:
                    if alert_id in self.active_alerts:
                        self.active_alerts[alert_id].resolved = True
                        self.active_alerts[alert_id].resolved_at = datetime.now()
                
                logger.info(f"Alerta resolvido: {alert_id}")
                
            except Exception as e:
                logger.error(f"Erro ao resolver alerta: {e}")
    
    def generate_dashboard_data(self, dashboard_name: str) -> Dict[str, Any]:
        """Gera dados para dashboard."""
        if dashboard_name not in self.dashboard_configs:
            return {}
        
        config = self.dashboard_configs[dashboard_name]
        dashboard_data = {
            "name": config.name,
            "description": config.description,
            "refresh_interval": config.refresh_interval,
            "timestamp": datetime.now().isoformat(),
            "metrics": {}
        }
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                for metric_name in config.metrics:
                    # Buscar m√©tricas dos √∫ltimos 24 horas
                    cursor.execute("""
                        SELECT value, timestamp, tags 
                        FROM performance_metrics 
                        WHERE name = ? 
                        AND timestamp >= datetime('now', '-24 hours')
                        ORDER BY timestamp DESC
                        LIMIT 1000
                    """, (metric_name,))
                    
                    rows = cursor.fetchall()
                    if rows:
                        values = [row[0] for row in rows]
                        timestamps = [row[1] for row in rows]
                        
                        dashboard_data["metrics"][metric_name] = {
                            "current": values[0],
                            "average": statistics.mean(values),
                            "min": min(values),
                            "max": max(values),
                            "history": list(zip(timestamps, values))
                        }
        
        except Exception as e:
            logger.error(f"Erro ao gerar dados do dashboard: {e}")
        
        return dashboard_data
    
    def create_performance_baseline(self, days: int = 7) -> Dict[str, Any]:
        """Cria baseline de performance baseado em dados hist√≥ricos."""
        baseline = {}
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Buscar m√©tricas dos √∫ltimos N dias
                cursor.execute("""
                    SELECT name, value, timestamp 
                    FROM performance_metrics 
                    WHERE timestamp >= datetime('now', '-{} days')
                    ORDER BY name, timestamp
                """.format(days))
                
                rows = cursor.fetchall()
                
                # Agrupar por m√©trica
                metrics_data = defaultdict(list)
                for row in rows:
                    metrics_data[row[0]].append(row[1])
                
                # Calcular estat√≠sticas para cada m√©trica
                for metric_name, values in metrics_data.items():
                    if len(values) > 10:  # M√≠nimo de amostras
                        baseline[metric_name] = {
                            "avg_value": statistics.mean(values),
                            "min_value": min(values),
                            "max_value": max(values),
                            "std_deviation": statistics.stdev(values) if len(values) > 1 else 0,
                            "sample_count": len(values),
                            "period_days": days
                        }
                
                # Armazenar baseline no banco
                period_start = datetime.now() - timedelta(days=days)
                period_end = datetime.now()
                
                for metric_name, stats in baseline.items():
                    cursor.execute("""
                        INSERT INTO performance_baseline 
                        (metric_name, avg_value, min_value, max_value, std_deviation, sample_count, period_start, period_end)
                        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                    """, (
                        metric_name,
                        stats["avg_value"],
                        stats["min_value"],
                        stats["max_value"],
                        stats["std_deviation"],
                        stats["sample_count"],
                        period_start.isoformat(),
                        period_end.isoformat()
                    ))
                
                conn.commit()
                
                self.baseline_data = baseline
                logger.info(f"Baseline criado para {len(baseline)} m√©tricas")
        
        except Exception as e:
            logger.error(f"Erro ao criar baseline: {e}")
        
        return baseline
    
    def start_monitoring(self):
        """Inicia monitoramento cont√≠nuo."""
        if self.monitoring_active:
            logger.warning("Monitoramento j√° est√° ativo")
            return
        
        self.monitoring_active = True
        
        def monitoring_loop():
            while self.monitoring_active:
                try:
                    # Coletar m√©tricas
                    system_metrics = self.collect_system_metrics()
                    app_metrics = self.collect_application_metrics()
                    db_metrics = self.collect_database_metrics()
                    
                    all_metrics = system_metrics + app_metrics + db_metrics
                    
                    # Armazenar m√©tricas
                    self.store_metrics(all_metrics)
                    
                    # Verificar alertas
                    self.check_alerts(all_metrics)
                    
                    # Aguardar pr√≥ximo ciclo
                    time.sleep(self.collection_interval)
                    
                except Exception as e:
                    logger.error(f"Erro no loop de monitoramento: {e}")
                    time.sleep(self.collection_interval)
        
        monitor_thread = threading.Thread(target=monitoring_loop, daemon=True)
        monitor_thread.start()
        
        logger.info("Monitoramento de performance iniciado")
    
    def stop_monitoring(self):
        """Para monitoramento cont√≠nuo."""
        self.monitoring_active = False
        logger.info("Monitoramento de performance parado")
    
    def get_active_alerts(self) -> List[Alert]:
        """Retorna alertas ativos."""
        with self.lock:
            return [alert for alert in self.active_alerts.values() if not alert.resolved]
    
    def get_metrics_summary(self) -> Dict[str, Any]:
        """Retorna resumo das m√©tricas."""
        summary = {
            "total_metrics": 0,
            "active_alerts": len(self.get_active_alerts()),
            "monitoring_active": self.monitoring_active,
            "baseline_available": len(self.baseline_data) > 0,
            "metrics_by_source": defaultdict(int)
        }
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # Total de m√©tricas
                cursor.execute("SELECT COUNT(*) FROM performance_metrics")
                summary["total_metrics"] = cursor.fetchone()[0]
                
                # M√©tricas por fonte
                cursor.execute("""
                    SELECT source, COUNT(*) 
                    FROM performance_metrics 
                    GROUP BY source
                """)
                
                for source, count in cursor.fetchall():
                    summary["metrics_by_source"][source] = count
        
        except Exception as e:
            logger.error(f"Erro ao gerar resumo: {e}")
        
        return summary
    
    def generate_monitoring_report(self) -> str:
        """Gera relat√≥rio completo do monitoramento."""
        summary = self.get_metrics_summary()
        active_alerts = self.get_active_alerts()
        
        report = f"""
# Relat√≥rio de Monitoramento de Performance - Omni Writer

**Data/Hora:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**Tracing ID:** PERFORMANCE_MONITORING_20250127_001

## üìä Resumo do Sistema

### M√©tricas Coletadas
- **Total de m√©tricas:** {summary['total_metrics']:,}
- **Monitoramento ativo:** {'‚úÖ' if summary['monitoring_active'] else '‚ùå'}
- **Baseline dispon√≠vel:** {'‚úÖ' if summary['baseline_available'] else '‚ùå'}

### M√©tricas por Fonte
"""
        
        for source, count in summary["metrics_by_source"].items():
            report += f"- **{source}:** {count:,} m√©tricas\n"
        
        report += f"""
## üö® Alertas Ativos

### Total de Alertas: {len(active_alerts)}
"""
        
        if active_alerts:
            for alert in active_alerts:
                report += f"""
### {alert.severity.upper()} - {alert.rule_name}
- **M√©trica:** {alert.metric_name}
- **Valor atual:** {alert.current_value}
- **Threshold:** {alert.threshold}
- **Mensagem:** {alert.message}
- **Timestamp:** {alert.timestamp.strftime('%Y-%m-%d %H:%M:%S')}
"""
        else:
            report += "‚úÖ Nenhum alerta ativo\n"
        
        report += f"""
## üìà Dashboards Dispon√≠veis

### Configurados: {len(self.dashboard_configs)}
"""
        
        for name, config in self.dashboard_configs.items():
            report += f"""
### {config.name}
- **Descri√ß√£o:** {config.description}
- **M√©tricas:** {', '.join(config.metrics)}
- **Refresh:** {config.refresh_interval}s
"""
        
        report += f"""
## üîß Configura√ß√µes

### Regras de Alerta: {len(self.alert_rules)}
### Intervalo de Coleta: {self.collection_interval}s
### Reten√ß√£o de Dados: {self.retention_days} dias
### M√°ximo de M√©tricas por Fonte: {self.max_metrics_per_source}

## üìÅ Arquivos do Sistema

### Banco de Dados
- **Localiza√ß√£o:** {self.db_path}
- **Tabelas:** performance_metrics, alerts, alert_rules, performance_baseline
- **√çndices:** Otimizados para consultas por nome e timestamp

### Dashboards
- **System Overview:** Vis√£o geral do sistema
- **Application Performance:** Performance da aplica√ß√£o
- **Database Performance:** Performance do banco

## üöÄ Pr√≥ximos Passos

1. **Configurar alertas por email/Slack**
2. **Integrar com Prometheus/Grafana**
3. **Implementar machine learning para detec√ß√£o de anomalias**
4. **Adicionar m√©tricas customizadas da aplica√ß√£o**

---
**Status:** ‚úÖ **MONITORAMENTO IMPLEMENTADO**
"""
        
        return report

def main():
    """Fun√ß√£o principal para demonstra√ß√£o do monitoramento."""
    logger.info("Iniciando demonstra√ß√£o do PerformanceMonitor...")
    
    # Criar monitor
    monitor = PerformanceMonitor()
    
    # Iniciar monitoramento
    monitor.start_monitoring()
    
    print("\n" + "="*60)
    print("üöÄ MONITORAMENTO DE PERFORMANCE INICIADO")
    print("="*60)
    print("üìä Coletando m√©tricas do sistema...")
    print("üö® Verificando alertas...")
    print("üìà Dashboards dispon√≠veis...")
    print("="*60)
    
    try:
        # Executar por 30 segundos para demonstra√ß√£o
        time.sleep(30)
        
        # Parar monitoramento
        monitor.stop_monitoring()
        
        # Gerar relat√≥rio
        report = monitor.generate_monitoring_report()
        
        # Salvar relat√≥rio
        report_path = f"performance_monitoring_report_{int(time.time())}.md"
        with open(report_path, "w", encoding="utf-8") as f:
            f.write(report)
        
        print("\n" + "="*60)
        print("‚úÖ MONITORAMENTO CONCLU√çDO")
        print("="*60)
        print(f"üìã Relat√≥rio salvo: {report_path}")
        print("üìä M√©tricas coletadas e analisadas")
        print("üö® Sistema de alertas funcionando")
        print("üìà Dashboards configurados")
        print("="*60)
        
    except KeyboardInterrupt:
        print("\n\n‚èπÔ∏è Monitoramento interrompido pelo usu√°rio")
        monitor.stop_monitoring()

if __name__ == "__main__":
    main() 