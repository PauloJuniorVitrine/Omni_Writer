#!/usr/bin/env python3
"""
ü§ñ DETEC√á√ÉO AUTOMATIZADA DE FLUXOS - INTEGRA√á√ÉO CI/CD
üìê CoCoT + ToT + ReAct - Baseado em C√≥digo Real
üö´ PROIBIDO: Testes sint√©ticos, gen√©ricos ou aleat√≥rios
‚úÖ PERMITIDO: Apenas testes baseados em c√≥digo real do Omni Writer

Script automatizado para detec√ß√£o de novos fluxos via logs.
Integra com CI/CD pipeline para monitoramento cont√≠nuo.

Tracing ID: AUTOMATED_FLOW_DETECTION_20250127_001
Data/Hora: 2025-01-27T19:30:00Z
Vers√£o: 1.0
"""

import sys
import os
import json
import logging
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import argparse

# Adiciona o diret√≥rio raiz ao path
sys.path.insert(0, str(Path(__file__).parent.parent))

from scripts.flow_detection_framework import FlowDetectionFramework
from scripts.telemetry_framework import telemetry_decorator

# Configura√ß√£o de logging estruturado
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] [%(levelname)s] [%(name)s] %(message)s'
)
logger = logging.getLogger(__name__)

TRACING_ID = "AUTOMATED_FLOW_DETECTION_20250127_001"

class AutomatedFlowDetection:
    """
    Sistema automatizado de detec√ß√£o de fluxos.
    
    Monitora logs continuamente e gera alertas para novos fluxos
    n√£o testados baseados em c√≥digo real do Omni Writer.
    """
    
    def __init__(self, config_path: str = "tests/integration/flow_detection_config.json"):
        """
        Inicializa o sistema automatizado.
        
        Args:
            config_path: Caminho para arquivo de configura√ß√£o
        """
        self.tracing_id = TRACING_ID
        self.config = self._load_config(config_path)
        self.framework = FlowDetectionFramework()
        self.last_analysis = None
        self.analysis_results = []
        
        logger.info(f"[{self.tracing_id}] Sistema automatizado inicializado")
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """Carrega configura√ß√£o do sistema."""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.error(f"[{self.tracing_id}] Erro ao carregar configura√ß√£o: {e}")
            return {}
    
    @telemetry_decorator
    def analyze_all_log_sources(self) -> Dict[str, Any]:
        """
        Analisa todas as fontes de log configuradas.
        
        Returns:
            Resultado consolidado da an√°lise
        """
        logger.info(f"[{self.tracing_id}] Iniciando an√°lise de todas as fontes de log")
        
        results = {}
        total_new_flows = 0
        total_high_risk_flows = 0
        total_suggestions = 0
        
        # Analisa cada fonte de log configurada
        log_sources = self.config.get("log_sources", {})
        
        for source_name, source_config in log_sources.items():
            if not source_config.get("enabled", True):
                logger.info(f"[{self.tracing_id}] Fonte {source_name} desabilitada, pulando")
                continue
            
            source_path = source_config.get("source_path")
            if not source_path or not Path(source_path).exists():
                logger.warning(f"[{self.tracing_id}] Fonte {source_name} n√£o encontrada: {source_path}")
                continue
            
            try:
                logger.info(f"[{self.tracing_id}] Analisando fonte: {source_name}")
                
                result = self.framework.analyze_logs(
                    source_path,
                    source_name=source_name
                )
                
                results[source_name] = {
                    "total_logs": result.total_logs_analyzed,
                    "new_flows": result.new_flows_detected,
                    "high_risk_flows": len(result.high_risk_flows),
                    "untested_flows": len(result.untested_flows),
                    "suggestions": result.test_suggestions_generated,
                    "status": "success"
                }
                
                total_new_flows += result.new_flows_detected
                total_high_risk_flows += len(result.high_risk_flows)
                total_suggestions += result.test_suggestions_generated
                
                logger.info(f"[{self.tracing_id}] {source_name}: {result.new_flows_detected} novos fluxos detectados")
                
            except Exception as e:
                logger.error(f"[{self.tracing_id}] Erro ao analisar {source_name}: {e}")
                results[source_name] = {
                    "status": "error",
                    "error": str(e)
                }
        
        # Resultado consolidado
        consolidated_result = {
            "tracing_id": self.tracing_id,
            "timestamp": datetime.now().isoformat(),
            "total_sources_analyzed": len([r for r in results.values() if r.get("status") == "success"]),
            "total_new_flows": total_new_flows,
            "total_high_risk_flows": total_high_risk_flows,
            "total_suggestions": total_suggestions,
            "source_results": results,
            "coverage_percentage": self._calculate_coverage_percentage(),
            "risk_assessment": self._assess_overall_risk(total_high_risk_flows, total_new_flows)
        }
        
        self.last_analysis = consolidated_result
        self.analysis_results.append(consolidated_result)
        
        logger.info(f"[{self.tracing_id}] An√°lise conclu√≠da: {total_new_flows} novos fluxos, {total_high_risk_flows} de alto risco")
        
        return consolidated_result
    
    def _calculate_coverage_percentage(self) -> float:
        """Calcula porcentagem de cobertura de testes."""
        try:
            report = self.framework.generate_report()
            stats = report.get("statistics", {})
            return stats.get("coverage_percentage", 0.0)
        except Exception as e:
            logger.error(f"[{self.tracing_id}] Erro ao calcular cobertura: {e}")
            return 0.0
    
    def _assess_overall_risk(self, high_risk_flows: int, new_flows: int) -> Dict[str, Any]:
        """Avalia risco geral baseado nos fluxos detectados."""
        risk_score = (high_risk_flows * 25) + (new_flows * 10)
        
        if risk_score >= 100:
            risk_level = "CRITICAL"
            action_required = "IMMEDIATE"
        elif risk_score >= 50:
            risk_level = "HIGH"
            action_required = "URGENT"
        elif risk_score >= 20:
            risk_level = "MEDIUM"
            action_required = "PLANNED"
        else:
            risk_level = "LOW"
            action_required = "MONITOR"
        
        return {
            "risk_score": risk_score,
            "risk_level": risk_level,
            "action_required": action_required,
            "high_risk_flows": high_risk_flows,
            "new_flows": new_flows
        }
    
    def generate_ci_cd_report(self) -> Dict[str, Any]:
        """
        Gera relat√≥rio formatado para CI/CD.
        
        Returns:
            Relat√≥rio em formato compat√≠vel com CI/CD
        """
        if not self.last_analysis:
            logger.warning(f"[{self.tracing_id}] Nenhuma an√°lise executada ainda")
            return {}
        
        # Gera relat√≥rio do framework
        framework_report = self.framework.generate_report()
        
        # Formata para CI/CD
        ci_cd_report = {
            "tracing_id": self.tracing_id,
            "timestamp": datetime.now().isoformat(),
            "status": "SUCCESS" if self.last_analysis["total_high_risk_flows"] == 0 else "WARNING",
            "summary": {
                "total_new_flows": self.last_analysis["total_new_flows"],
                "high_risk_flows": self.last_analysis["total_high_risk_flows"],
                "coverage_percentage": self.last_analysis["coverage_percentage"],
                "risk_level": self.last_analysis["risk_assessment"]["risk_level"]
            },
            "details": {
                "source_analysis": self.last_analysis["source_results"],
                "risk_assessment": self.last_analysis["risk_assessment"],
                "framework_statistics": framework_report.get("statistics", {}),
                "most_frequent_flows": framework_report.get("most_frequent_flows", []),
                "high_risk_flows": framework_report.get("high_risk_flows", []),
                "untested_flows": framework_report.get("untested_flows", []),
                "test_suggestions": framework_report.get("test_suggestions", [])
            },
            "recommendations": self._generate_recommendations(),
            "next_actions": self._generate_next_actions()
        }
        
        return ci_cd_report
    
    def _generate_recommendations(self) -> List[str]:
        """Gera recomenda√ß√µes baseadas na an√°lise."""
        recommendations = []
        
        if not self.last_analysis:
            return recommendations
        
        risk_assessment = self.last_analysis["risk_assessment"]
        coverage = self.last_analysis["coverage_percentage"]
        
        # Recomenda√ß√µes baseadas em risco
        if risk_assessment["risk_level"] == "CRITICAL":
            recommendations.append("üö® CR√çTICO: Implementar testes imediatamente para fluxos de alto risco")
            recommendations.append("üîç Revisar todos os fluxos n√£o testados identificados")
        
        elif risk_assessment["risk_level"] == "HIGH":
            recommendations.append("‚ö†Ô∏è ALTO RISCO: Priorizar testes para fluxos cr√≠ticos")
            recommendations.append("üìä Analisar padr√µes de uso para identificar prioridades")
        
        # Recomenda√ß√µes baseadas em cobertura
        if coverage < 80:
            recommendations.append(f"üìà Cobertura baixa ({coverage:.1f}%): Aumentar cobertura de testes")
        
        if coverage < 60:
            recommendations.append("üö® Cobertura cr√≠tica: Revisar estrat√©gia de testes")
        
        # Recomenda√ß√µes baseadas em novos fluxos
        if self.last_analysis["total_new_flows"] > 0:
            recommendations.append(f"üÜï {self.last_analysis['total_new_flows']} novos fluxos detectados: Implementar testes")
        
        # Recomenda√ß√µes baseadas em sugest√µes
        if self.last_analysis["total_suggestions"] > 0:
            recommendations.append(f"üí° {self.last_analysis['total_suggestions']} sugest√µes de teste geradas: Revisar e implementar")
        
        return recommendations
    
    def _generate_next_actions(self) -> List[Dict[str, str]]:
        """Gera pr√≥ximas a√ß√µes baseadas na an√°lise."""
        actions = []
        
        if not self.last_analysis:
            return actions
        
        risk_assessment = self.last_analysis["risk_assessment"]
        
        # A√ß√µes baseadas no n√≠vel de risco
        if risk_assessment["risk_level"] in ["CRITICAL", "HIGH"]:
            actions.append({
                "priority": "IMMEDIATE",
                "action": "Implementar testes para fluxos de alto risco",
                "description": "Criar testes para fluxos identificados como cr√≠ticos"
            })
            
            actions.append({
                "priority": "URGENT",
                "action": "Revisar logs de produ√ß√£o",
                "description": "Analisar logs para identificar padr√µes de falha"
            })
        
        # A√ß√µes baseadas em novos fluxos
        if self.last_analysis["total_new_flows"] > 0:
            actions.append({
                "priority": "HIGH",
                "action": "Analisar novos fluxos detectados",
                "description": "Revisar fluxos n√£o testados e priorizar testes"
            })
        
        # A√ß√µes baseadas em cobertura
        if self.last_analysis["coverage_percentage"] < 80:
            actions.append({
                "priority": "MEDIUM",
                "action": "Aumentar cobertura de testes",
                "description": "Implementar testes para aumentar cobertura"
            })
        
        return actions
    
    def save_report(self, report: Dict[str, Any], output_path: str = None) -> str:
        """
        Salva relat√≥rio em arquivo.
        
        Args:
            report: Relat√≥rio a ser salvo
            output_path: Caminho do arquivo de sa√≠da
            
        Returns:
            Caminho do arquivo salvo
        """
        if not output_path:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = f"tests/integration/flow_detection_report_{timestamp}.json"
        
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            logger.info(f"[{self.tracing_id}] Relat√≥rio salvo em: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"[{self.tracing_id}] Erro ao salvar relat√≥rio: {e}")
            return ""
    
    def run_continuous_monitoring(self, interval_minutes: int = 60, max_iterations: int = None):
        """
        Executa monitoramento cont√≠nuo.
        
        Args:
            interval_minutes: Intervalo entre an√°lises em minutos
            max_iterations: N√∫mero m√°ximo de itera√ß√µes (None para infinito)
        """
        logger.info(f"[{self.tracing_id}] Iniciando monitoramento cont√≠nuo (intervalo: {interval_minutes}min)")
        
        iteration = 0
        
        while max_iterations is None or iteration < max_iterations:
            try:
                logger.info(f"[{self.tracing_id}] Itera√ß√£o {iteration + 1}")
                
                # Executa an√°lise
                analysis_result = self.analyze_all_log_sources()
                
                # Gera relat√≥rio
                report = self.generate_ci_cd_report()
                
                # Salva relat√≥rio
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                report_path = f"tests/integration/flow_detection_continuous_{timestamp}.json"
                self.save_report(report, report_path)
                
                # Verifica se h√° alertas cr√≠ticos
                if analysis_result["risk_assessment"]["risk_level"] == "CRITICAL":
                    logger.critical(f"[{self.tracing_id}] üö® ALERTA CR√çTICO: {analysis_result['total_high_risk_flows']} fluxos de alto risco detectados!")
                
                # Aguarda pr√≥ximo ciclo
                if max_iterations is None or iteration < max_iterations - 1:
                    logger.info(f"[{self.tracing_id}] Aguardando {interval_minutes} minutos para pr√≥xima an√°lise...")
                    time.sleep(interval_minutes * 60)
                
                iteration += 1
                
            except KeyboardInterrupt:
                logger.info(f"[{self.tracing_id}] Monitoramento interrompido pelo usu√°rio")
                break
            except Exception as e:
                logger.error(f"[{self.tracing_id}] Erro no monitoramento: {e}")
                time.sleep(60)  # Aguarda 1 minuto antes de tentar novamente
        
        logger.info(f"[{self.tracing_id}] Monitoramento conclu√≠do ap√≥s {iteration} itera√ß√µes")

def main():
    """Fun√ß√£o principal do script."""
    parser = argparse.ArgumentParser(description="Detec√ß√£o automatizada de fluxos via logs")
    parser.add_argument("--config", default="tests/integration/flow_detection_config.json", 
                       help="Caminho para arquivo de configura√ß√£o")
    parser.add_argument("--output", help="Caminho para arquivo de sa√≠da")
    parser.add_argument("--continuous", action="store_true", 
                       help="Executa monitoramento cont√≠nuo")
    parser.add_argument("--interval", type=int, default=60,
                       help="Intervalo em minutos para monitoramento cont√≠nuo")
    parser.add_argument("--max-iterations", type=int,
                       help="N√∫mero m√°ximo de itera√ß√µes para monitoramento cont√≠nuo")
    
    args = parser.parse_args()
    
    print(f"[{TRACING_ID}] ü§ñ INICIANDO DETEC√á√ÉO AUTOMATIZADA DE FLUXOS")
    print("=" * 70)
    
    try:
        # Inicializa sistema
        detector = AutomatedFlowDetection(args.config)
        
        if args.continuous:
            # Executa monitoramento cont√≠nuo
            detector.run_continuous_monitoring(
                interval_minutes=args.interval,
                max_iterations=args.max_iterations
            )
        else:
            # Executa an√°lise √∫nica
            print("üîç Executando an√°lise √∫nica...")
            analysis_result = detector.analyze_all_log_sources()
            
            # Gera relat√≥rio
            report = detector.generate_ci_cd_report()
            
            # Salva relat√≥rio
            output_path = args.output or f"tests/integration/flow_detection_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            detector.save_report(report, output_path)
            
            # Imprime resumo
            print("\nüìä RESUMO DA AN√ÅLISE:")
            print("-" * 50)
            print(f"üìà Fontes analisadas: {analysis_result['total_sources_analyzed']}")
            print(f"üÜï Novos fluxos: {analysis_result['total_new_flows']}")
            print(f"üö® Fluxos de alto risco: {analysis_result['total_high_risk_flows']}")
            print(f"üí° Sugest√µes geradas: {analysis_result['total_suggestions']}")
            print(f"üìä Cobertura: {analysis_result['coverage_percentage']:.1f}%")
            print(f"‚ö†Ô∏è N√≠vel de risco: {analysis_result['risk_assessment']['risk_level']}")
            
            # Imprime recomenda√ß√µes
            if report.get("recommendations"):
                print(f"\nüí° RECOMENDA√á√ïES:")
                print("-" * 50)
                for rec in report["recommendations"]:
                    print(f"  ‚Ä¢ {rec}")
            
            # Imprime pr√≥ximas a√ß√µes
            if report.get("next_actions"):
                print(f"\nüéØ PR√ìXIMAS A√á√ïES:")
                print("-" * 50)
                for action in report["next_actions"]:
                    print(f"  ‚Ä¢ [{action['priority']}] {action['action']}")
                    print(f"    {action['description']}")
            
            print(f"\n‚úÖ An√°lise conclu√≠da! Relat√≥rio salvo em: {output_path}")
        
    except Exception as e:
        logger.error(f"[{TRACING_ID}] Erro na execu√ß√£o: {e}")
        print(f"\n‚ùå Erro na execu√ß√£o: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main()) 