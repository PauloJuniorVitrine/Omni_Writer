#!/usr/bin/env python3
"""
Sistema de Testes Incrementais E2E
- Executa apenas testes que mudaram
- An√°lise de depend√™ncias entre testes
- Cache de resultados
- Otimiza√ß√£o de execu√ß√£o

üìê CoCoT: Baseado em boas pr√°ticas de testes incrementais
üå≤ ToT: M√∫ltiplas estrat√©gias de an√°lise implementadas
‚ôªÔ∏è ReAct: Simulado para diferentes cen√°rios de mudan√ßas

**Prompt:** Interface Gr√°fica v3.5 Enterprise+ - TEST-001
**Data/Hora:** 2025-01-28T11:45:00Z
**Tracing ID:** INCREMENTAL_TESTS_md1ppfhs
**Origem:** Necessidade de otimiza√ß√£o de execu√ß√£o de testes E2E
"""

import os
import json
import hashlib
import subprocess
import argparse
from pathlib import Path
from typing import Dict, List, Set, Any, Optional
from dataclasses import dataclass
from datetime import datetime
try:
    import git
except ImportError:
    git = None

@dataclass
class TestFile:
    """Arquivo de teste"""
    path: str
    hash: str
    dependencies: List[str]
    last_modified: datetime
    last_executed: Optional[datetime]
    execution_time: float
    status: str  # 'passed', 'failed', 'skipped'

@dataclass
class ChangeSet:
    """Conjunto de mudan√ßas"""
    modified_files: List[str]
    added_files: List[str]
    deleted_files: List[str]
    commit_hash: str
    timestamp: datetime

class IncrementalTestRunner:
    """Executor de testes incrementais"""
    
    def __init__(self, test_dir: str = 'tests/e2e', cache_dir: str = '.incremental-cache'):
        self.test_dir = Path(test_dir)
        self.cache_dir = Path(cache_dir)
        self.metadata_file = self.cache_dir / 'test-metadata.json'
        self.changes_file = self.cache_dir / 'changes.json'
        
        # Configura√ß√µes
        self.config = {
            'enable_incremental': True,
            'max_cache_age': 24 * 60 * 60,  # 24 horas
            'dependency_analysis': True,
            'parallel_execution': True,
            'fallback_to_full': True
        }
        
        # Inicializar
        self._init_cache()
        self.test_files: Dict[str, TestFile] = self._load_metadata()
        self.changes: ChangeSet = self._load_changes()
    
    def _init_cache(self) -> None:
        """Inicializar cache"""
        if not self.cache_dir.exists():
            self.cache_dir.mkdir(parents=True, exist_ok=True)
            print(f"üìÅ Cache incremental criado em: {self.cache_dir}")
    
    def _load_metadata(self) -> Dict[str, TestFile]:
        """Carregar metadados dos testes"""
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                test_files = {}
                for path, file_data in data.items():
                    test_files[path] = TestFile(
                        path=file_data['path'],
                        hash=file_data['hash'],
                        dependencies=file_data.get('dependencies', []),
                        last_modified=datetime.fromisoformat(file_data['last_modified']),
                        last_executed=datetime.fromisoformat(file_data['last_executed']) if file_data.get('last_executed') else None,
                        execution_time=file_data.get('execution_time', 0),
                        status=file_data.get('status', 'unknown')
                    )
                return test_files
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao carregar metadados: {e}")
                return {}
        return {}
    
    def _save_metadata(self) -> None:
        """Salvar metadados dos testes"""
        try:
            data = {}
            for path, test_file in self.test_files.items():
                data[path] = {
                    'path': test_file.path,
                    'hash': test_file.hash,
                    'dependencies': test_file.dependencies,
                    'last_modified': test_file.last_modified.isoformat(),
                    'last_executed': test_file.last_executed.isoformat() if test_file.last_executed else None,
                    'execution_time': test_file.execution_time,
                    'status': test_file.status
                }
            
            with open(self.metadata_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao salvar metadados: {e}")
    
    def _load_changes(self) -> ChangeSet:
        """Carregar informa√ß√µes de mudan√ßas"""
        if self.changes_file.exists():
            try:
                with open(self.changes_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                return ChangeSet(
                    modified_files=data.get('modified_files', []),
                    added_files=data.get('added_files', []),
                    deleted_files=data.get('deleted_files', []),
                    commit_hash=data.get('commit_hash', ''),
                    timestamp=datetime.fromisoformat(data['timestamp'])
                )
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao carregar mudan√ßas: {e}")
        
        return ChangeSet([], [], [], '', datetime.now())
    
    def _save_changes(self) -> None:
        """Salvar informa√ß√µes de mudan√ßas"""
        try:
            data = {
                'modified_files': self.changes.modified_files,
                'added_files': self.changes.added_files,
                'deleted_files': self.changes.deleted_files,
                'commit_hash': self.changes.commit_hash,
                'timestamp': self.changes.timestamp.isoformat()
            }
            
            with open(self.changes_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao salvar mudan√ßas: {e}")
    
    def _get_file_hash(self, file_path: Path) -> str:
        """Calcular hash do arquivo"""
        try:
            with open(file_path, 'rb') as f:
                return hashlib.sha256(f.read()).hexdigest()
        except Exception:
            return ''
    
    def _analyze_dependencies(self, test_file: Path) -> List[str]:
        """Analisar depend√™ncias do arquivo de teste"""
        dependencies = []
        
        try:
            with open(test_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Depend√™ncias baseadas em imports
            import_patterns = [
                r'import.*from\s+[\'"]([^\'"]+)[\'"]',
                r'require\s*\(\s*[\'"]([^\'"]+)[\'"]',
                r'from\s+[\'"]([^\'"]+)[\'"]'
            ]
            
            import re
            for pattern in import_patterns:
                matches = re.findall(pattern, content)
                dependencies.extend(matches)
            
            # Depend√™ncias baseadas em refer√™ncias de c√≥digo
            code_patterns = [
                r'app/([^\s\'"`]+)',
                r'ui/([^\s\'"`]+)',
                r'shared/([^\s\'"`]+)',
                r'services/([^\s\'"`]+)'
            ]
            
            for pattern in code_patterns:
                matches = re.findall(pattern, content)
                dependencies.extend(matches)
            
            # Remover duplicatas
            return list(set(dependencies))
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao analisar depend√™ncias de {test_file}: {e}")
            return []
    
    def _detect_changes(self, base_commit: str = None) -> ChangeSet:
        """Detectar mudan√ßas no reposit√≥rio"""
        if git is None:
            print("‚ö†Ô∏è GitPython n√£o instalado, usando detec√ß√£o b√°sica de mudan√ßas")
            return self._detect_changes_basic()
        
        try:
            repo = git.Repo('.')
            
            if base_commit:
                # Comparar com commit espec√≠fico
                diff = repo.commit(base_commit).diff(repo.head.commit)
            else:
                # Comparar com √∫ltimo commit
                commits = list(repo.iter_commits(max_count=2))
                if len(commits) > 1:
                    diff = commits[1].diff(commits[0])
                else:
                    # Primeiro commit
                    diff = []
            
            modified_files = []
            added_files = []
            deleted_files = []
            
            for change in diff:
                if change.change_type == 'M':
                    modified_files.append(change.a_path)
                elif change.change_type == 'A':
                    added_files.append(change.a_path)
                elif change.change_type == 'D':
                    deleted_files.append(change.b_path)
            
            changes = ChangeSet(
                modified_files=modified_files,
                added_files=added_files,
                deleted_files=deleted_files,
                commit_hash=repo.head.commit.hexsha,
                timestamp=datetime.now()
            )
            
            self.changes = changes
            self._save_changes()
            
            return changes
            
        except Exception as e:
            print(f"‚ö†Ô∏è Erro ao detectar mudan√ßas: {e}")
            return self._detect_changes_basic()
    
    def _detect_changes_basic(self) -> ChangeSet:
        """Detec√ß√£o b√°sica de mudan√ßas baseada em timestamp"""
        modified_files = []
        
        # Verificar arquivos modificados baseado em timestamp
        for test_file in self.test_dir.rglob('*.spec.ts'):
            if str(test_file) in self.test_files:
                cached_file = self.test_files[str(test_file)]
                if test_file.stat().st_mtime > cached_file.last_modified.timestamp():
                    modified_files.append(str(test_file))
        
        return ChangeSet(
            modified_files=modified_files,
            added_files=[],
            deleted_files=[],
            commit_hash='',
            timestamp=datetime.now()
        )
    
    def _scan_test_files(self) -> Dict[str, TestFile]:
        """Escaneiar arquivos de teste"""
        test_files = {}
        
        for test_file in self.test_dir.rglob('*.spec.ts'):
            try:
                file_hash = self._get_file_hash(test_file)
                dependencies = self._analyze_dependencies(test_file)
                last_modified = datetime.fromtimestamp(test_file.stat().st_mtime)
                
                # Verificar se j√° existe no cache
                if str(test_file) in self.test_files:
                    cached_file = self.test_files[str(test_file)]
                    last_executed = cached_file.last_executed
                    execution_time = cached_file.execution_time
                    status = cached_file.status
                else:
                    last_executed = None
                    execution_time = 0
                    status = 'unknown'
                
                test_files[str(test_file)] = TestFile(
                    path=str(test_file),
                    hash=file_hash,
                    dependencies=dependencies,
                    last_modified=last_modified,
                    last_executed=last_executed,
                    execution_time=execution_time,
                    status=status
                )
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro ao escanear {test_file}: {e}")
        
        return test_files
    
    def _get_affected_tests(self) -> Set[str]:
        """Obter testes afetados pelas mudan√ßas"""
        affected_tests = set()
        
        # Testes que mudaram diretamente
        for modified_file in self.changes.modified_files:
            if modified_file.endswith('.spec.ts'):
                affected_tests.add(modified_file)
        
        # Testes que dependem de arquivos modificados
        for test_path, test_file in self.test_files.items():
            for dependency in test_file.dependencies:
                for modified_file in self.changes.modified_files:
                    if dependency in modified_file or modified_file in dependency:
                        affected_tests.add(test_path)
                        break
        
        # Testes que dependem de depend√™ncias modificadas
        for test_path, test_file in self.test_files.items():
            for dependency in test_file.dependencies:
                for modified_file in self.changes.modified_files:
                    if any(dep in modified_file for dep in dependency.split('/')):
                        affected_tests.add(test_path)
                        break
        
        return affected_tests
    
    def _get_tests_to_run(self, force_full: bool = False) -> List[str]:
        """Determinar quais testes executar"""
        if force_full or not self.config['enable_incremental']:
            print("üîÑ Executando suite completa de testes")
            return list(self.test_files.keys())
        
        # Escanear arquivos de teste
        self.test_files = self._scan_test_files()
        
        # Detectar mudan√ßas
        changes = self._detect_changes()
        
        if not any([changes.modified_files, changes.added_files, changes.deleted_files]):
            print("‚úÖ Nenhuma mudan√ßa detectada")
            return []
        
        # Obter testes afetados
        affected_tests = self._get_affected_tests()
        
        # Verificar se h√° mudan√ßas significativas
        if len(affected_tests) > len(self.test_files) * 0.5:
            print("‚ö†Ô∏è Muitos testes afetados, executando suite completa")
            return list(self.test_files.keys())
        
        # Verificar se h√° mudan√ßas em arquivos cr√≠ticos
        critical_files = ['package.json', 'playwright.config.ts', 'global-setup.ts']
        if any(critical in changes.modified_files for critical in critical_files):
            print("‚ö†Ô∏è Mudan√ßas em arquivos cr√≠ticos, executando suite completa")
            return list(self.test_files.keys())
        
        print(f"üéØ Executando {len(affected_tests)} testes incrementais")
        return list(affected_tests)
    
    def run_tests(self, test_files: List[str], parallel: bool = True) -> Dict[str, Any]:
        """Executar testes"""
        if not test_files:
            return {'success': True, 'message': 'Nenhum teste para executar'}
        
        results = {
            'total': len(test_files),
            'passed': 0,
            'failed': 0,
            'skipped': 0,
            'execution_time': 0,
            'details': {}
        }
        
        start_time = datetime.now()
        
        try:
            # Construir comando
            test_paths = ' '.join(test_files)
            cmd = f"npx playwright test {test_paths}"
            
            if parallel:
                cmd += " --workers=auto"
            
            print(f"üöÄ Executando: {cmd}")
            
            # Executar testes
            result = subprocess.run(
                cmd,
                shell=True,
                capture_output=True,
                text=True,
                timeout=3600  # 1 hora timeout
            )
            
            # Analisar resultados
            execution_time = (datetime.now() - start_time).total_seconds()
            results['execution_time'] = execution_time
            
            if result.returncode == 0:
                results['success'] = True
                results['passed'] = len(test_files)
                print(f"‚úÖ Testes executados com sucesso em {execution_time:.2f}s")
            else:
                results['success'] = False
                results['failed'] = len(test_files)
                print(f"‚ùå Testes falharam em {execution_time:.2f}s")
            
            # Atualizar metadados
            for test_file in test_files:
                if test_file in self.test_files:
                    self.test_files[test_file].last_executed = datetime.now()
                    self.test_files[test_file].execution_time = execution_time / len(test_files)
                    self.test_files[test_file].status = 'passed' if results['success'] else 'failed'
            
            self._save_metadata()
            
        except subprocess.TimeoutExpired:
            results['success'] = False
            results['message'] = 'Timeout na execu√ß√£o dos testes'
            print("‚è∞ Timeout na execu√ß√£o dos testes")
        except Exception as e:
            results['success'] = False
            results['message'] = str(e)
            print(f"‚ùå Erro na execu√ß√£o: {e}")
        
        return results
    
    def run_incremental(self, force_full: bool = False, parallel: bool = True) -> Dict[str, Any]:
        """Executar testes incrementais"""
        print("üîç Analisando mudan√ßas para execu√ß√£o incremental...")
        
        # Obter testes para executar
        test_files = self._get_tests_to_run(force_full)
        
        if not test_files:
            return {
                'success': True,
                'message': 'Nenhum teste para executar',
                'incremental': True,
                'tests_executed': 0
            }
        
        # Executar testes
        results = self.run_tests(test_files, parallel)
        results['incremental'] = True
        results['tests_executed'] = len(test_files)
        
        return results
    
    def print_summary(self) -> None:
        """Exibir resumo dos testes"""
        total_tests = len(self.test_files)
        executed_tests = len([tf for tf in self.test_files.values() if tf.last_executed])
        passed_tests = len([tf for tf in self.test_files.values() if tf.status == 'passed'])
        failed_tests = len([tf for tf in self.test_files.values() if tf.status == 'failed'])
        
        print("\nüìä RESUMO DOS TESTES INCREMENTAIS")
        print("=" * 40)
        print(f"Total de testes: {total_tests}")
        print(f"Testes executados: {executed_tests}")
        print(f"Testes passaram: {passed_tests}")
        print(f"Testes falharam: {failed_tests}")
        
        if self.changes.commit_hash:
            print(f"√öltimo commit: {self.changes.commit_hash[:8]}")
            print(f"Arquivos modificados: {len(self.changes.modified_files)}")
            print(f"Arquivos adicionados: {len(self.changes.added_files)}")
            print(f"Arquivos removidos: {len(self.changes.deleted_files)}")

def main():
    """Fun√ß√£o principal"""
    parser = argparse.ArgumentParser(description='Executor de Testes Incrementais E2E')
    parser.add_argument('--test-dir', default='tests/e2e', help='Diret√≥rio de testes')
    parser.add_argument('--cache-dir', default='.incremental-cache', help='Diret√≥rio do cache')
    parser.add_argument('--force-full', action='store_true', help='For√ßar execu√ß√£o completa')
    parser.add_argument('--no-parallel', action='store_true', help='Desabilitar execu√ß√£o paralela')
    parser.add_argument('--base-commit', help='Commit base para compara√ß√£o')
    parser.add_argument('--summary', action='store_true', help='Exibir resumo')
    
    args = parser.parse_args()
    
    runner = IncrementalTestRunner(args.test_dir, args.cache_dir)
    
    if args.summary:
        runner.print_summary()
    else:
        # Executar testes incrementais
        results = runner.run_incremental(
            force_full=args.force_full,
            parallel=not args.no_parallel
        )
        
        # Exibir resultados
        if results['success']:
            print(f"‚úÖ Execu√ß√£o conclu√≠da: {results['tests_executed']} testes executados")
        else:
            print(f"‚ùå Execu√ß√£o falhou: {results.get('message', 'Erro desconhecido')}")
        
        # Exibir resumo
        runner.print_summary()

if __name__ == '__main__':
    main() 