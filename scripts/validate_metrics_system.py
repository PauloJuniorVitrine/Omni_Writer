#!/usr/bin/env python3
"""
Script de ValidaÃ§Ã£o - Metrics System
====================================

Valida o sistema de mÃ©tricas Prometheus/Grafana.
Verifica mÃ©tricas, alertas e dashboard.

Prompt: Script de validaÃ§Ã£o para sistema de mÃ©tricas
Ruleset: enterprise_control_layer.yaml
Data/Hora: 2025-01-27T10:50:00Z
"""

import os
import sys
import logging
import requests
import json
from datetime import datetime
import time

# Adiciona o diretÃ³rio raiz ao path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

def setup_logging():
    """Configura logging para validaÃ§Ã£o."""
    logging.basicConfig(
        level=logging.INFO,
        format='[%(asctime)s] [%(levelname)s] [validation] %(message)s',
        handlers=[
            logging.FileHandler('logs/exec_trace/metrics_validation.log'),
            logging.StreamHandler()
        ]
    )
    return logging.getLogger(__name__)

def validate_imports():
    """Valida se todas as dependÃªncias estÃ£o disponÃ­veis."""
    logger = logging.getLogger(__name__)
    
    required_modules = [
        'shared.metrics_system',
        'prometheus_client'
    ]
    
    missing_modules = []
    
    for module in required_modules:
        try:
            __import__(module)
            logger.info(f"âœ… MÃ³dulo {module} disponÃ­vel")
        except ImportError as e:
            logger.error(f"âŒ MÃ³dulo {module} nÃ£o disponÃ­vel: {e}")
            missing_modules.append(module)
    
    return len(missing_modules) == 0

def validate_metrics_system():
    """Valida o sistema de mÃ©tricas."""
    logger = logging.getLogger(__name__)
    
    try:
        from shared.metrics_system import MetricsSystem, metrics_system
        
        # Testa criaÃ§Ã£o do sistema
        system = MetricsSystem()
        
        # Testa mÃ©tricas bÃ¡sicas
        system.record_article_generation('gpt-4', 'completed', 'user123', 2.5)
        system.record_request('POST', '/generate', 200, 1.2)
        system.record_token_usage('gpt-4', 'user123', 'success')
        
        logger.info(f"âœ… Sistema de mÃ©tricas criado com sucesso")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no sistema de mÃ©tricas: {e}")
        return False

def validate_metrics_endpoint():
    """Valida endpoint de mÃ©tricas."""
    logger = logging.getLogger(__name__)
    
    try:
        # Testa endpoint de mÃ©tricas
        response = requests.get('http://localhost:5000/metrics', timeout=5)
        
        if response.status_code == 200:
            data = response.json()
            logger.info(f"âœ… Endpoint de mÃ©tricas funcionando")
            logger.info(f"ğŸ“Š Dados recebidos: {json.dumps(data, indent=2)}")
            return True
        else:
            logger.error(f"âŒ Endpoint de mÃ©tricas retornou status {response.status_code}")
            return False
            
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ Erro ao acessar endpoint de mÃ©tricas: {e}")
        return False

def validate_dashboard():
    """Valida dashboard de mÃ©tricas."""
    logger = logging.getLogger(__name__)
    
    try:
        # Testa dashboard
        response = requests.get('http://localhost:5000/dashboard', timeout=5)
        
        if response.status_code == 200:
            logger.info(f"âœ… Dashboard funcionando")
            return True
        else:
            logger.error(f"âŒ Dashboard retornou status {response.status_code}")
            return False
            
    except requests.exceptions.RequestException as e:
        logger.error(f"âŒ Erro ao acessar dashboard: {e}")
        return False

def validate_prometheus_metrics():
    """Valida mÃ©tricas Prometheus."""
    logger = logging.getLogger(__name__)
    
    try:
        from shared.metrics_system import metrics_system
        
        # Testa geraÃ§Ã£o de mÃ©tricas Prometheus
        metrics_data = metrics_system.get_metrics()
        
        if metrics_data and len(metrics_data) > 0:
            logger.info(f"âœ… MÃ©tricas Prometheus geradas com sucesso")
            logger.info(f"ğŸ“Š Tamanho das mÃ©tricas: {len(metrics_data)} bytes")
            return True
        else:
            logger.error(f"âŒ MÃ©tricas Prometheus vazias")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Erro ao gerar mÃ©tricas Prometheus: {e}")
        return False

def validate_metrics_summary():
    """Valida resumo de mÃ©tricas."""
    logger = logging.getLogger(__name__)
    
    try:
        from shared.metrics_system import get_metrics_summary
        
        # Testa resumo de mÃ©tricas
        summary = get_metrics_summary()
        
        if summary and isinstance(summary, dict):
            logger.info(f"âœ… Resumo de mÃ©tricas gerado com sucesso")
            logger.info(f"ğŸ“Š Estrutura: {list(summary.keys())}")
            return True
        else:
            logger.error(f"âŒ Resumo de mÃ©tricas invÃ¡lido")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Erro ao gerar resumo de mÃ©tricas: {e}")
        return False

def validate_alert_system():
    """Valida sistema de alertas."""
    logger = logging.getLogger(__name__)
    
    try:
        from shared.metrics_system import metrics_system
        
        # Simula condiÃ§Ãµes de alerta
        metrics_system.error_rate.set(0.05)  # 5% de erro
        metrics_system.avg_latency.set(6.0)   # 6s de latÃªncia
        
        # ForÃ§a verificaÃ§Ã£o de alertas
        metrics_system._check_alerts()
        
        logger.info(f"âœ… Sistema de alertas funcionando")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no sistema de alertas: {e}")
        return False

def validate_metrics_recording():
    """Valida gravaÃ§Ã£o de mÃ©tricas."""
    logger = logging.getLogger(__name__)
    
    try:
        from shared.metrics_system import (
            record_article_generation,
            record_request,
            record_token_usage,
            record_error
        )
        
        # Testa gravaÃ§Ã£o de diferentes tipos de mÃ©tricas
        record_article_generation('gpt-4', 'completed', 'user123', 2.5)
        record_request('POST', '/generate', 200, 1.2)
        record_token_usage('gpt-4', 'user123', 'success')
        record_error('api_error', '/generate', 'user123')
        
        logger.info(f"âœ… GravaÃ§Ã£o de mÃ©tricas funcionando")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro na gravaÃ§Ã£o de mÃ©tricas: {e}")
        return False

def validate_metrics_port():
    """Valida porta de mÃ©tricas."""
    logger = logging.getLogger(__name__)
    
    try:
        import socket
        
        # Testa se a porta de mÃ©tricas estÃ¡ disponÃ­vel
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        result = sock.connect_ex(('localhost', 9090))
        sock.close()
        
        if result == 0:
            logger.info(f"âœ… Porta de mÃ©tricas (9090) disponÃ­vel")
            return True
        else:
            logger.warning(f"âš ï¸ Porta de mÃ©tricas (9090) nÃ£o disponÃ­vel")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Erro ao verificar porta de mÃ©tricas: {e}")
        return False

def validate_file_structure():
    """Valida estrutura de arquivos necessÃ¡ria."""
    logger = logging.getLogger(__name__)
    
    required_files = [
        'shared/metrics_system.py',
        'templates/metrics_dashboard.html',
        'logs/exec_trace/'
    ]
    
    missing_files = []
    
    for file_path in required_files:
        if not os.path.exists(file_path):
            missing_files.append(file_path)
            logger.error(f"âŒ Arquivo/diretÃ³rio nÃ£o encontrado: {file_path}")
        else:
            logger.info(f"âœ… Arquivo/diretÃ³rio encontrado: {file_path}")
    
    return len(missing_files) == 0

def validate_logging():
    """Valida sistema de logging."""
    logger = logging.getLogger(__name__)
    
    try:
        import logging
        
        # Verifica se o logger de metrics system existe
        metrics_logger = logging.getLogger("metrics_system")
        
        assert metrics_logger.level == logging.INFO
        assert len(metrics_logger.handlers) > 0
        
        # Testa escrita de log
        test_message = f"Teste de logging - {datetime.utcnow().isoformat()}"
        metrics_logger.info(test_message)
        
        logger.info("âœ… Sistema de logging funcionando")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Erro no sistema de logging: {e}")
        return False

def run_validation():
    """Executa todas as validaÃ§Ãµes."""
    logger = setup_logging()
    
    logger.info("ğŸš€ Iniciando validaÃ§Ã£o do sistema de mÃ©tricas")
    logger.info("=" * 60)
    
    validations = [
        ("Estrutura de arquivos", validate_file_structure),
        ("ImportaÃ§Ãµes", validate_imports),
        ("Sistema de mÃ©tricas", validate_metrics_system),
        ("Endpoint de mÃ©tricas", validate_metrics_endpoint),
        ("Dashboard", validate_dashboard),
        ("MÃ©tricas Prometheus", validate_prometheus_metrics),
        ("Resumo de mÃ©tricas", validate_metrics_summary),
        ("Sistema de alertas", validate_alert_system),
        ("GravaÃ§Ã£o de mÃ©tricas", validate_metrics_recording),
        ("Porta de mÃ©tricas", validate_metrics_port),
        ("Sistema de logging", validate_logging)
    ]
    
    results = []
    
    for name, validation_func in validations:
        logger.info(f"\nğŸ” Validando: {name}")
        try:
            result = validation_func()
            results.append((name, result))
            if result:
                logger.info(f"âœ… {name}: OK")
            else:
                logger.error(f"âŒ {name}: FALHOU")
        except Exception as e:
            logger.error(f"âŒ {name}: ERRO - {e}")
            results.append((name, False))
    
    # Resumo final
    logger.info("\n" + "=" * 60)
    logger.info("ğŸ“‹ RESUMO DA VALIDAÃ‡ÃƒO")
    logger.info("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        logger.info(f"{status} - {name}")
    
    logger.info(f"\nğŸ“Š Resultado: {passed}/{total} validaÃ§Ãµes passaram")
    
    if passed == total:
        logger.info("ğŸ‰ TODAS AS VALIDAÃ‡Ã•ES PASSARAM!")
        return True
    else:
        logger.error("âš ï¸ ALGUMAS VALIDAÃ‡Ã•ES FALHARAM!")
        return False

if __name__ == "__main__":
    success = run_validation()
    sys.exit(0 if success else 1) 