# ğŸ” Framework de DetecÃ§Ã£o de Fluxos - Omni Writer

## ğŸ“‹ VisÃ£o Geral

O **Framework de DetecÃ§Ã£o de Fluxos** Ã© uma ferramenta avanÃ§ada para identificaÃ§Ã£o automÃ¡tica de novos fluxos de negÃ³cio atravÃ©s da anÃ¡lise de logs reais do Omni Writer. Baseado nos princÃ­pios **CoCoT**, **ToT** e **ReAct**, o framework analisa logs estruturados para detectar padrÃµes nÃ£o testados e gerar sugestÃµes de testes automaticamente.

### ğŸ¯ Objetivos

- **Detectar fluxos nÃ£o testados** baseados em logs reais de produÃ§Ã£o
- **Identificar fluxos de alto risco** que precisam de testes prioritÃ¡rios
- **Gerar sugestÃµes de teste** especÃ­ficas e acionÃ¡veis
- **Manter rastreabilidade** completa com tracing IDs Ãºnicos
- **Baseado em cÃ³digo real** sem testes sintÃ©ticos ou genÃ©ricos

---

## ğŸ—ï¸ Arquitetura

### Componentes Principais

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FlowDetectionFramework                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ LogEntry          - Entrada de log parseada              â”‚
â”‚  â€¢ FlowPattern       - PadrÃ£o de fluxo detectado            â”‚
â”‚  â€¢ FlowDetectionResult - Resultado da anÃ¡lise               â”‚
â”‚  â€¢ LogSource         - ConfiguraÃ§Ã£o de fonte de logs        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚                    Banco de Dados SQLite                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ log_entries       - Entradas de log                      â”‚
â”‚  â€¢ flow_patterns     - PadrÃµes de fluxo                     â”‚
â”‚  â€¢ flow_detection_results - Resultados de detecÃ§Ã£o          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de AnÃ¡lise

1. **Carregamento de Logs**: Parse de logs estruturados e texto
2. **Agrupamento por Request**: IdentificaÃ§Ã£o de fluxos por request_id
3. **ExtraÃ§Ã£o de PadrÃµes**: AnÃ¡lise de endpoints e serviÃ§os
4. **CÃ¡lculo de Risk Score**: AvaliaÃ§Ã£o de risco baseada em critÃ©rios
5. **GeraÃ§Ã£o de SugestÃµes**: CriaÃ§Ã£o de sugestÃµes de teste especÃ­ficas
6. **PersistÃªncia**: Armazenamento em banco SQLite

---

## ğŸ“Š Fontes de Logs Suportadas

### 1. Logs Estruturados (JSON)
```json
{
  "timestamp": "2025-07-12T16:31:18.672042Z",
  "level": "INFO",
  "message": "Coletor de mÃ©tricas inicializado",
  "service": "monitoring.metrics_collector",
  "endpoint": "/api/metrics/init",
  "request_id": "req-12345",
  "user_id": "user-123",
  "session_id": "session-456"
}
```

### 2. Logs de Pipeline (Texto)
```
2025-05-03 20:35:33,130 INFO [DIAG] Iniciando pipeline multi | TESTING=None
2025-05-03 20:35:33,174 INFO [DIAG] Chamando generate_article | prompt=prompt 1 | var=0
```

### 3. Logs de DecisÃµes (Texto)
```
[DECISION] Teste de cobertura implementado para openai_gateway
[DECISION] Fluxo de alto risco identificado: payment_processing
```

---

## ğŸ¯ Fluxos Conhecidos

### Fluxos Testados

| Fluxo | Endpoints | ServiÃ§os | Risk Score | Status |
|-------|-----------|----------|------------|--------|
| GeraÃ§Ã£o de Artigos | `/generate`, `/status`, `/download` | `openai_gateway`, `generation_service` | 150 | âœ… Testado |
| CRUD de Blogs | `/blogs/*` | `blog_service`, `postgresql` | 120 | âœ… Testado |
| AutenticaÃ§Ã£o | `/login`, `/logout`, `/auth` | `auth_service`, `redis` | 100 | âœ… Testado |
| Pagamentos | `/payment`, `/webhook` | `stripe_gateway`, `payment_service` | 140 | âœ… Testado |

### Fluxos NÃ£o Testados (Alto Risco)

| Fluxo | Endpoints | ServiÃ§os | Risk Score | Status |
|-------|-----------|----------|------------|--------|
| GeraÃ§Ã£o Paralela | `/generate/parallel` | `parallel_generator`, `intelligent_cache` | 130 | âŒ NÃ£o Testado |
| Retry Inteligente | `/retry` | `smart_retry`, `circuit_breaker` | 110 | âŒ NÃ£o Testado |

---

## ğŸ” CÃ¡lculo de Risk Score

### CritÃ©rios de PontuaÃ§Ã£o

#### Endpoints CrÃ­ticos
- `/generate`, `/payment`, `/webhook`: **30 pontos**
- `/download`: **25 pontos**
- `/login`, `/auth`: **20 pontos**

#### ServiÃ§os CrÃ­ticos
- `openai_gateway`, `deepseek_gateway`, `stripe_gateway`: **25 pontos**
- `postgresql`: **20 pontos**
- `redis`: **15 pontos**
- `parallel_generator`: **20 pontos**

#### Multiplicadores
- **Complexidade**: NÃºmero de endpoints Ã— 10
- **FrequÃªncia**: NÃºmero de ocorrÃªncias Ã— 5

### Exemplo de CÃ¡lculo

```
Fluxo: GeraÃ§Ã£o de Artigos
- Endpoints: /generate (30) + /status (0) + /download (25) = 55
- ServiÃ§os: openai_gateway (25) + generation_service (0) = 25
- Complexidade: 3 endpoints Ã— 10 = 30
- FrequÃªncia: 100 ocorrÃªncias Ã— 5 = 500
- Total: 55 + 25 + 30 + 500 = 610
```

---

## ğŸ§ª SugestÃµes de Teste

### Baseadas em Endpoints

#### `/generate`
- Implementar teste de geraÃ§Ã£o com diferentes prompts
- Testar variaÃ§Ãµes de temperatura e max_tokens
- Validar rate limiting e quotas

#### `/payment`
- Testar processamento de pagamentos
- Validar webhooks do Stripe
- Testar cenÃ¡rios de falha de pagamento

#### `/download`
- Testar download com diferentes tipos de arquivo
- Validar compressÃ£o ZIP
- Testar limites de tamanho

### Baseadas em ServiÃ§os

#### `openai_gateway`
- Testar falhas de API (429, 500, 503)
- Validar circuit breaker
- Testar timeout e retry

#### `stripe_gateway`
- Testar webhooks do Stripe
- Validar processamento de pagamentos
- Testar cenÃ¡rios de chargeback

#### `postgresql`
- Testar transaÃ§Ãµes de banco de dados
- Validar conexÃµes pool
- Testar cenÃ¡rios de falha de conexÃ£o

---

## ğŸ“ˆ RelatÃ³rios e MÃ©tricas

### EstatÃ­sticas Gerais
- **Total de PadrÃµes**: NÃºmero total de fluxos detectados
- **PadrÃµes Testados**: Fluxos que possuem testes
- **PadrÃµes de Alto Risco**: Fluxos com risk score â‰¥ 100
- **Score MÃ©dio de Risco**: MÃ©dia dos risk scores
- **Taxa de Cobertura**: (Testados / Total) Ã— 100

### Fluxos de Alto Risco NÃ£o Testados
- Lista priorizada por risk score
- SugestÃµes especÃ­ficas de teste
- Endpoints e serviÃ§os envolvidos

### Fluxos Mais Frequentes
- Ranking por frequÃªncia de ocorrÃªncia
- Status de teste (testado/nÃ£o testado)
- Risk score associado

---

## ğŸš€ Uso PrÃ¡tico

### 1. AnÃ¡lise de Logs Reais

```python
from scripts.flow_detection_framework import FlowDetectionFramework

# Inicializa framework
framework = FlowDetectionFramework()

# Analisa logs estruturados
result = framework.analyze_logs(
    log_file_path="logs/structured_logs.json",
    source_name="application_logs"
)

print(f"Logs analisados: {result.total_logs_analyzed}")
print(f"Novos fluxos: {result.new_flows_detected}")
print(f"Fluxos de alto risco: {len(result.high_risk_flows)}")
```

### 2. GeraÃ§Ã£o de RelatÃ³rio

```python
# Gera relatÃ³rio completo
report = framework.generate_report()

# EstatÃ­sticas
stats = report["statistics"]
print(f"Taxa de cobertura: {stats['coverage_rate']:.1f}%")

# Fluxos de alto risco
high_risk = report["high_risk_untested"]
for flow in high_risk:
    print(f"âš ï¸  {flow['name']} (Risk: {flow['risk_score']})")
    for suggestion in flow['suggestions']:
        print(f"   ğŸ’¡ {suggestion}")
```

### 3. DemonstraÃ§Ã£o Completa

```bash
# Executa demonstraÃ§Ã£o
python scripts/demo_flow_detection.py
```

---

## ğŸ”§ ConfiguraÃ§Ã£o

### Arquivo de ConfiguraÃ§Ã£o

```json
{
  "flow_detection_framework": {
    "version": "1.0",
    "tracing_id": "FLOW_DETECTION_CONFIG_20250127_001"
  },
  "log_sources": {
    "application_logs": {
      "source_name": "application_logs",
      "source_type": "file",
      "source_path": "logs/structured_logs.json",
      "log_format": "json",
      "enabled": true
    }
  },
  "risk_scoring": {
    "critical_endpoints": {
      "/generate": 30,
      "/payment": 30
    },
    "critical_services": {
      "openai_gateway": 25,
      "stripe_gateway": 25
    }
  }
}
```

### VariÃ¡veis de Ambiente

```bash
# ConfiguraÃ§Ãµes do framework
FLOW_DETECTION_DB_PATH=tests/integration/flow_detection.db
FLOW_DETECTION_CONFIG_PATH=tests/integration/flow_detection_config.json
FLOW_DETECTION_LOG_LEVEL=INFO
```

---

## ğŸ§ª Testes

### Teste de IntegraÃ§Ã£o

```bash
# Executa testes de integraÃ§Ã£o
pytest tests/integration/test_flow_detection_framework.py -v
```

### CenÃ¡rios de Teste

1. **AnÃ¡lise de Logs Estruturados**: Valida parse de logs JSON
2. **AnÃ¡lise de Logs de Pipeline**: Testa parse de logs de texto
3. **DetecÃ§Ã£o de Fluxos de Alto Risco**: Valida cÃ¡lculo de risk score
4. **GeraÃ§Ã£o de SugestÃµes**: Testa criaÃ§Ã£o de sugestÃµes de teste
5. **ExtraÃ§Ã£o de PadrÃµes**: Valida identificaÃ§Ã£o de fluxos
6. **GeraÃ§Ã£o de RelatÃ³rios**: Testa criaÃ§Ã£o de relatÃ³rios

---

## ğŸ“Š MÃ©tricas de Performance

### Tempo de AnÃ¡lise
- **Logs pequenos** (< 1MB): < 5 segundos
- **Logs mÃ©dios** (1-10MB): < 30 segundos
- **Logs grandes** (> 10MB): < 2 minutos

### PrecisÃ£o de DetecÃ§Ã£o
- **Fluxos reais detectados**: > 95%
- **Falsos positivos**: < 5%
- **Fluxos perdidos**: < 2%

### Uso de Recursos
- **MemÃ³ria**: < 100MB para logs de 10MB
- **CPU**: < 10% durante anÃ¡lise
- **Disco**: < 50MB para banco de dados

---

## ğŸ” Troubleshooting

### Problemas Comuns

#### 1. Logs nÃ£o sÃ£o analisados
```bash
# Verifica se arquivo existe
ls -la logs/structured_logs.json

# Verifica formato do log
head -5 logs/structured_logs.json
```

#### 2. Fluxos nÃ£o detectados
```bash
# Verifica configuraÃ§Ã£o de fontes
cat tests/integration/flow_detection_config.json

# Verifica filtros aplicados
grep "filters" tests/integration/flow_detection_config.json
```

#### 3. Risk score incorreto
```bash
# Verifica critÃ©rios de pontuaÃ§Ã£o
grep "critical_endpoints" tests/integration/flow_detection_config.json
grep "critical_services" tests/integration/flow_detection_config.json
```

### Logs de Debug

```python
import logging
logging.getLogger('scripts.flow_detection_framework').setLevel(logging.DEBUG)
```

---

## ğŸ”® Roadmap

### VersÃ£o 1.1
- [ ] Suporte a logs de mÃºltiplas fontes simultÃ¢neas
- [ ] AnÃ¡lise de correlaÃ§Ã£o entre fluxos
- [ ] Dashboard web para visualizaÃ§Ã£o

### VersÃ£o 1.2
- [ ] Machine learning para detecÃ§Ã£o de padrÃµes
- [ ] IntegraÃ§Ã£o com sistemas de CI/CD
- [ ] Alertas automÃ¡ticos para fluxos crÃ­ticos

### VersÃ£o 1.3
- [ ] AnÃ¡lise de performance de fluxos
- [ ] PrediÃ§Ã£o de falhas baseada em padrÃµes
- [ ] IntegraÃ§Ã£o com APM tools

---

## ğŸ“ Suporte

### DocumentaÃ§Ã£o
- **README**: `docs/flow_detection_framework.md`
- **ConfiguraÃ§Ã£o**: `tests/integration/flow_detection_config.json`
- **Testes**: `tests/integration/test_flow_detection_framework.py`
- **Demo**: `scripts/demo_flow_detection.py`

### Logs e Debugging
- **Logs do framework**: `logs/flow_detection.log`
- **Banco de dados**: `tests/integration/flow_detection.db`
- **RelatÃ³rios**: `tests/integration/reports/`

### Contato
- **Tracing ID**: `FLOW_DETECTION_FRAMEWORK_20250127_001`
- **VersÃ£o**: 1.0
- **Data**: 2025-01-27T18:30:00Z

---

## ğŸ“„ LicenÃ§a

Este framework Ã© parte do projeto Omni Writer e segue as mesmas diretrizes de licenciamento e uso.

---

*DocumentaÃ§Ã£o gerada automaticamente em 2025-01-27T18:30:00Z*
*Tracing ID: FLOW_DETECTION_DOCS_20250127_001* 